{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":34595,"sourceType":"datasetVersion","datasetId":26922},{"sourceId":8181593,"sourceType":"datasetVersion","datasetId":4843948}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# importing important libraries and its functionalities\nimport os\nimport cv2\nimport numpy as np\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom skimage.feature import hog\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier","metadata":{"id":"1vyoII0m7YUl","execution":{"iopub.status.busy":"2024-04-21T08:10:09.217739Z","iopub.execute_input":"2024-04-21T08:10:09.218910Z","iopub.status.idle":"2024-04-21T08:10:09.227305Z","shell.execute_reply.started":"2024-04-21T08:10:09.218842Z","shell.execute_reply":"2024-04-21T08:10:09.225981Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import os\nfrom zipfile import ZipFile\n\n\n!pip install kaggle\n\n\nos.environ['KAGGLE_USERNAME'] = \"majisouvik1099\"\nos.environ['KAGGLE_KEY'] = \"9464225218d56f8bfea9dd9cc437489f\"\n\n# download the datset needed\n!kaggle datasets download -d jessicali9530/lfw-dataset\n\n# extract the files by unzipping\nwith ZipFile('lfw-dataset.zip', 'r') as zip_ref:\n    zip_ref.extractall('lfw-dataset')\n\n\nos.remove('lfw-dataset.zip')\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F_1HCdqdOk1s","outputId":"62ae2229-8cc1-4ccd-acef-04407371f563","execution":{"iopub.status.busy":"2024-04-21T08:10:09.691582Z","iopub.execute_input":"2024-04-21T08:10:09.691995Z","iopub.status.idle":"2024-04-21T08:10:32.014697Z","shell.execute_reply.started":"2024-04-21T08:10:09.691962Z","shell.execute_reply":"2024-04-21T08:10:32.013493Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (1.6.12)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle) (1.16.0)\nRequirement already satisfied: certifi>=2023.7.22 in /opt/conda/lib/python3.10/site-packages (from kaggle) (2024.2.2)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle) (2.9.0.post0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle) (4.66.1)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle) (8.0.4)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle) (1.26.18)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle) (6.1.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle) (0.5.1)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle) (1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle) (3.6)\nDataset URL: https://www.kaggle.com/datasets/jessicali9530/lfw-dataset\nLicense(s): other\nDownloading lfw-dataset.zip to /kaggle/working\n 98%|███████████████████████████████████████▏| 110M/112M [00:04<00:00, 31.6MB/s]\n100%|████████████████████████████████████████| 112M/112M [00:04<00:00, 26.1MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# defining some of the important functions that are needed \n\n# defining feature extraction for resnet-50\ndef extract_features(image_path, model):\n    image = Image.open(image_path).convert('RGB')\n    preprocess = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n    image = preprocess(image)\n    image = image.unsqueeze(0)\n    with torch.no_grad():\n        features = model(image)\n    features = features.squeeze(0)\n    return features\n\n# hog calculation\ndef compute_hog(img):\n    resized_img = resize(img, (128*4, 64*4))\n    fd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8),\n                    cells_per_block=(2, 2), visualize=True,channel_axis=-1)\n    return fd\n\n\ndef get_pixel(img, center, x, y):\n    new_value = 0\n    try:\n        if img[x][y] >= center:\n            new_value = 1\n    except:\n        pass\n    return new_value\n\n# calculate lbp\n\ndef lbp_calculated_pixel(img, x, y):\n    center = img[x][y]\n    val_ar = []\n    val_ar.append(get_pixel(img, center, x-1, y+1))\n    val_ar.append(get_pixel(img, center, x, y+1))\n    val_ar.append(get_pixel(img, center, x+1, y+1))\n    val_ar.append(get_pixel(img, center, x+1, y))\n    val_ar.append(get_pixel(img, center, x+1, y-1))\n    val_ar.append(get_pixel(img, center, x, y-1))\n    val_ar.append(get_pixel(img, center, x-1, y-1))\n    val_ar.append(get_pixel(img, center, x-1, y))\n\n    power_val = [1, 2, 4, 8, 16, 32, 64, 128]\n    val = 0\n    for i in range(len(val_ar)):\n        val += val_ar[i] * power_val[i]\n    return val\n\ndef calcLBP(img):\n    height, width, channel = img.shape\n    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img_lbp = np.zeros((height, width,3), np.uint8)\n    for i in range(0, height):\n        for j in range(0, width):\n             img_lbp[i, j] = lbp_calculated_pixel(img_gray, i, j)\n    hist_lbp = cv2.calcHist([img_lbp], [0], None, [256], [0, 256])\n    return hist_lbp.flatten()\n","metadata":{"id":"0gADFqRHIgLP","execution":{"iopub.status.busy":"2024-04-21T08:10:32.017483Z","iopub.execute_input":"2024-04-21T08:10:32.017814Z","iopub.status.idle":"2024-04-21T08:10:32.033136Z","shell.execute_reply.started":"2024-04-21T08:10:32.017782Z","shell.execute_reply":"2024-04-21T08:10:32.032111Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# pretrained resnet-50 model\nresnet = models.resnet50(pretrained=True)\nresnet = nn.Sequential(*list(resnet.children())[:-1])\nresnet.eval()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JUycN27qIo3O","outputId":"b08ac631-81af-4e5b-8bc5-a61eb1dba2d6","execution":{"iopub.status.busy":"2024-04-21T08:10:32.034953Z","iopub.execute_input":"2024-04-21T08:10:32.035348Z","iopub.status.idle":"2024-04-21T08:10:32.669662Z","shell.execute_reply.started":"2024-04-21T08:10:32.035314Z","shell.execute_reply":"2024-04-21T08:10:32.668564Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Sequential(\n  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU(inplace=True)\n  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (5): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (6): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (7): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n)"},"metadata":{}}]},{"cell_type":"code","source":"# extracting the features from the folder\nlfw_folder = '/kaggle/input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled'\nX, y = [], []\nfor folder_name in os.listdir(lfw_folder):\n    folder_path = os.path.join(lfw_folder, folder_name)\n    if os.path.isdir(folder_path):\n        num_images = len(os.listdir(folder_path))\n        if num_images > 50: # taking those persons who have atleast 70 images \n            for image_name in os.listdir(folder_path):\n                image_path = os.path.join(folder_path, image_name)\n                image = imread(image_path)\n                hog_feature = compute_hog(image) # hog features\n                lbp_feature = calcLBP(image)     # lbp features\n                cnn_feature = extract_features(image_path, resnet).numpy() #cnn features\n                hog_feature = hog_feature.reshape(-1) \n                lbp_feature = lbp_feature.reshape(-1)\n                cnn_feature = cnn_feature.flatten()\n                combined_feature = np.concatenate((hog_feature, lbp_feature, cnn_feature)) # combining features as needed\n\n                X.append(combined_feature)\n                y.append(folder_name)\n","metadata":{"id":"wZjeqVQKnMcK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6facf535-cdb4-47f6-932e-6725d7448b40","execution":{"iopub.status.busy":"2024-04-21T08:10:32.672009Z","iopub.execute_input":"2024-04-21T08:10:32.672359Z","iopub.status.idle":"2024-04-21T08:35:59.156152Z","shell.execute_reply.started":"2024-04-21T08:10:32.672332Z","shell.execute_reply":"2024-04-21T08:35:59.154823Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# hog features extracted\nhog_feature","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mUofteubfY_C","outputId":"3619593a-ad6c-4b04-b9f1-4e05892e656a","execution":{"iopub.status.busy":"2024-04-21T07:37:15.652682Z","iopub.execute_input":"2024-04-21T07:37:15.653480Z","iopub.status.idle":"2024-04-21T07:37:15.660751Z","shell.execute_reply.started":"2024-04-21T07:37:15.653450Z","shell.execute_reply":"2024-04-21T07:37:15.659732Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"array([0., 0., 0., ..., 0., 0., 0.])"},"metadata":{}}]},{"cell_type":"code","source":"# printing the shape\nnp.array(X).shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jwXoqblCx22_","outputId":"cc4088cf-2ed8-4e71-e5b3-c3889abcb9a0","execution":{"iopub.status.busy":"2024-04-21T08:47:14.548171Z","iopub.execute_input":"2024-04-21T08:47:14.548789Z","iopub.status.idle":"2024-04-21T08:47:14.848055Z","shell.execute_reply.started":"2024-04-21T08:47:14.548751Z","shell.execute_reply":"2024-04-21T08:47:14.846927Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"(1288, 72612)"},"metadata":{}}]},{"cell_type":"code","source":"# train-test split \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)","metadata":{"id":"MCUtZ8Feo1k3","execution":{"iopub.status.busy":"2024-04-21T08:47:21.278021Z","iopub.execute_input":"2024-04-21T08:47:21.278533Z","iopub.status.idle":"2024-04-21T08:47:21.287021Z","shell.execute_reply.started":"2024-04-21T08:47:21.278495Z","shell.execute_reply":"2024-04-21T08:47:21.285096Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nimport numpy as np\n\n# Grid\nparam_grid = {'C': np.logspace(-3, 3, 7)}\n\n# L1 regularization\nlasso_logreg = LogisticRegression(penalty='l1', solver='liblinear', max_iter=10000)\n\n# find the best hyperparameters\ngrid_search = GridSearchCV(lasso_logreg, param_grid, cv=5)\n\ngrid_search.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T04:08:24.477972Z","iopub.execute_input":"2024-04-21T04:08:24.478437Z","iopub.status.idle":"2024-04-21T05:52:57.986074Z","shell.execute_reply.started":"2024-04-21T04:08:24.478393Z","shell.execute_reply":"2024-04-21T05:52:57.983985Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=5,\n             estimator=LogisticRegression(max_iter=10000, penalty='l1',\n                                          solver='liblinear'),\n             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])})","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n             estimator=LogisticRegression(max_iter=10000, penalty=&#x27;l1&#x27;,\n                                          solver=&#x27;liblinear&#x27;),\n             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n             estimator=LogisticRegression(max_iter=10000, penalty=&#x27;l1&#x27;,\n                                          solver=&#x27;liblinear&#x27;),\n             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"# best model\nbest_lasso_logreg = grid_search.best_estimator_\n\n# Fit the model\nbest_lasso_logreg.fit(X_train, y_train)\n\n# prediction\ny_pred = best_lasso_logreg.predict(X_test)\n\n# Evaluation\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n# classification report\nreport = classification_report(y_test, y_pred)\n\nprint(\"Classification Report:\\n\", report)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T05:52:57.989193Z","iopub.execute_input":"2024-04-21T05:52:57.990108Z","iopub.status.idle":"2024-04-21T05:54:21.679361Z","shell.execute_reply.started":"2024-04-21T05:52:57.990058Z","shell.execute_reply":"2024-04-21T05:54:21.675508Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Accuracy: 0.9573643410852714\nClassification Report:\n                    precision    recall  f1-score   support\n\n     Ariel_Sharon       1.00      0.86      0.92        14\n     Colin_Powell       0.93      0.93      0.93        43\n  Donald_Rumsfeld       1.00      1.00      1.00        24\n    George_W_Bush       0.97      0.98      0.98       124\nGerhard_Schroeder       0.94      0.94      0.94        18\n      Hugo_Chavez       0.92      0.92      0.92        13\n       Tony_Blair       0.91      0.91      0.91        22\n\n         accuracy                           0.96       258\n        macro avg       0.95      0.94      0.94       258\n     weighted avg       0.96      0.96      0.96       258\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# prediction\ny_pred = best_lasso_logreg.predict(X_train)\n\n# Evaluation\naccuracy = accuracy_score(y_train, y_pred)\nprint(\"Accuracy:\", accuracy)\n# classification report\nreport = classification_report(y_train, y_pred)\n\nprint(\"Classification Report:\\n\", report)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T05:54:21.681255Z","iopub.execute_input":"2024-04-21T05:54:21.682026Z","iopub.status.idle":"2024-04-21T05:54:22.128785Z","shell.execute_reply.started":"2024-04-21T05:54:21.681984Z","shell.execute_reply":"2024-04-21T05:54:22.125518Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Accuracy: 1.0\nClassification Report:\n                    precision    recall  f1-score   support\n\n     Ariel_Sharon       1.00      1.00      1.00        63\n     Colin_Powell       1.00      1.00      1.00       193\n  Donald_Rumsfeld       1.00      1.00      1.00        97\n    George_W_Bush       1.00      1.00      1.00       406\nGerhard_Schroeder       1.00      1.00      1.00        91\n      Hugo_Chavez       1.00      1.00      1.00        58\n       Tony_Blair       1.00      1.00      1.00       122\n\n         accuracy                           1.00      1030\n        macro avg       1.00      1.00      1.00      1030\n     weighted avg       1.00      1.00      1.00      1030\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# This is the best model we have found, so we will generate pickle file of this model and demo code using this model\ndemo1 = LogisticRegression(C=1000, penalty='l1', solver='liblinear', max_iter=10000)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:47:26.386532Z","iopub.execute_input":"2024-04-21T08:47:26.386996Z","iopub.status.idle":"2024-04-21T08:47:26.392585Z","shell.execute_reply.started":"2024-04-21T08:47:26.386962Z","shell.execute_reply":"2024-04-21T08:47:26.391351Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# fitting the model with the whole data\ndemo1.fit(X,y)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:47:29.016064Z","iopub.execute_input":"2024-04-21T08:47:29.016450Z","iopub.status.idle":"2024-04-21T08:48:35.173223Z","shell.execute_reply.started":"2024-04-21T08:47:29.016424Z","shell.execute_reply":"2024-04-21T08:48:35.172119Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(C=1000, max_iter=10000, penalty='l1', solver='liblinear')","text/html":"<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1000, max_iter=10000, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1000, max_iter=10000, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"import pickle\n\n# generating pickle file of the pretrained model\nwith open('demo1.pkl', 'wb') as f:\n    pickle.dump(demo1, f)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T08:48:35.175204Z","iopub.execute_input":"2024-04-21T08:48:35.175954Z","iopub.status.idle":"2024-04-21T08:48:35.187117Z","shell.execute_reply.started":"2024-04-21T08:48:35.175912Z","shell.execute_reply":"2024-04-21T08:48:35.186089Z"},"trusted":true},"execution_count":35,"outputs":[]}]}