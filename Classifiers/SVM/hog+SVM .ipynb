{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1vyoII0m7YUl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from skimage.feature import hog\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_1HCdqdOk1s",
        "outputId": "0730bf1f-38c0-43a3-c591-2ef5a11da6a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n",
            "Downloading lfw-dataset.zip to /content\n",
            " 82% 92.0M/112M [00:00<00:00, 192MB/s]\n",
            "100% 112M/112M [00:00<00:00, 178MB/s] \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "\n",
        "!pip install kaggle\n",
        "\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = \"majisouvik1099\"\n",
        "os.environ['KAGGLE_KEY'] = \"9464225218d56f8bfea9dd9cc437489f\"\n",
        "\n",
        "\n",
        "!kaggle datasets download -d jessicali9530/lfw-dataset\n",
        "\n",
        "\n",
        "with ZipFile('lfw-dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('lfw-dataset')\n",
        "\n",
        "\n",
        "os.remove('lfw-dataset.zip')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0gADFqRHIgLP"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_features(image_path, model):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    image = preprocess(image)\n",
        "    image = image.unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        features = model(image)\n",
        "    features = features.squeeze(0)\n",
        "    return features\n",
        "\n",
        "\n",
        "def compute_hog(img):\n",
        "    resized_img = resize(img, (128*4, 64*4))\n",
        "    fd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8),\n",
        "                    cells_per_block=(2, 2), visualize=True, multichannel=True)\n",
        "    return fd\n",
        "\n",
        "\n",
        "def get_pixel(img, center, x, y):\n",
        "    new_value = 0\n",
        "    try:\n",
        "        if img[x][y] >= center:\n",
        "            new_value = 1\n",
        "    except:\n",
        "        pass\n",
        "    return new_value\n",
        "\n",
        "def lbp_calculated_pixel(img, x, y):\n",
        "    center = img[x][y]\n",
        "    val_ar = []\n",
        "    val_ar.append(get_pixel(img, center, x-1, y+1))\n",
        "    val_ar.append(get_pixel(img, center, x, y+1))\n",
        "    val_ar.append(get_pixel(img, center, x+1, y+1))\n",
        "    val_ar.append(get_pixel(img, center, x+1, y))\n",
        "    val_ar.append(get_pixel(img, center, x+1, y-1))\n",
        "    val_ar.append(get_pixel(img, center, x, y-1))\n",
        "    val_ar.append(get_pixel(img, center, x-1, y-1))\n",
        "    val_ar.append(get_pixel(img, center, x-1, y))\n",
        "\n",
        "    power_val = [1, 2, 4, 8, 16, 32, 64, 128]\n",
        "    val = 0\n",
        "    for i in range(len(val_ar)):\n",
        "        val += val_ar[i] * power_val[i]\n",
        "    return val\n",
        "\n",
        "def calcLBP(img):\n",
        "    height, width, channel = img.shape\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img_lbp = np.zeros((height, width,3), np.uint8)\n",
        "    for i in range(0, height):\n",
        "        for j in range(0, width):\n",
        "             img_lbp[i, j] = lbp_calculated_pixel(img_gray, i, j)\n",
        "    hist_lbp = cv2.calcHist([img_lbp], [0], None, [256], [0, 256])\n",
        "    return hist_lbp.flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUycN27qIo3O",
        "outputId": "9c904562-1798-4448-ba59-aaf20d4c8080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 84.5MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): ReLU(inplace=True)\n",
              "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (6): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (7): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "resnet = models.resnet50(pretrained=True)\n",
        "resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
        "resnet.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZjeqVQKnMcK",
        "outputId": "3a7eda34-c63e-4d59-b5d7-4f6fce0292aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-8d0f7df1f55f>:19: FutureWarning: `multichannel` is a deprecated argument name for `hog`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  fd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8),\n"
          ]
        }
      ],
      "source": [
        "lfw_folder = '/content/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled'\n",
        "X, y = [], []\n",
        "for folder_name in os.listdir(lfw_folder):\n",
        "    folder_path = os.path.join(lfw_folder, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "        num_images = len(os.listdir(folder_path))\n",
        "        if num_images > 70:\n",
        "            for image_name in os.listdir(folder_path):\n",
        "                image_path = os.path.join(folder_path, image_name)\n",
        "                image = imread(image_path)\n",
        "                hog_feature = compute_hog(image)\n",
        "                # lbp_feature = calcLBP(image)\n",
        "                # cnn_feature = extract_features(image_path, resnet).numpy()\n",
        "                hog_feature = hog_feature.reshape(-1)\n",
        "                # lbp_feature = lbp_feature.reshape(-1)\n",
        "                # cnn_feature = cnn_feature.flatten()\n",
        "                # combined_feature = np.concatenate((hog_feature, lbp_feature, cnn_feature))\n",
        "\n",
        "                X.append(hog_feature)\n",
        "                y.append(folder_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MCUtZ8Feo1k3"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4lxiJIBvqJY4"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEwdH7OKlaxS",
        "outputId": "57455e18-20d7-4d7f-c201-cbb512203468"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tuning hyperparameters via grid search\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid search best score: 88.74%\n",
            "grid search best parameters: {'C': 0.1, 'kernel': 'linear'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = [\n",
        "        {\"kernel\":\n",
        "            [\"linear\"],\n",
        "            \"C\": [ 0.1, 1, 10, 100]},\n",
        "        {\"kernel\":\n",
        "            [\"poly\"],\n",
        "            \"degree\": [2, 3, 4],\n",
        "            \"C\": [ 0.1, 1, 10, 100]},\n",
        "        {\"kernel\":\n",
        "            [\"rbf\"],\n",
        "            \"gamma\": [\"auto\", \"scale\"],\n",
        "            \"C\": [ 0.1, 1, 10, 100]}\n",
        "]\n",
        "\n",
        "svm_clf = SVC()\n",
        "print(\"tuning hyperparameters via grid search\")\n",
        "grid = GridSearchCV(estimator=SVC(), param_grid=parameters, n_jobs=-1)\n",
        "grid.fit(X_train,y_train_encoded)\n",
        "print(f\"grid search best score: {grid.best_score_ * 100:.2f}%\")\n",
        "print(f\"grid search best parameters: {grid.best_params_}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SgpBOIfclc_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2319f31c-a4df-4a12-c225-d4a259a42c37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Classifier\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Ariel_Sharon       0.92      0.79      0.85        14\n",
            "     Colin_Powell       0.93      0.95      0.94        40\n",
            "  Donald_Rumsfeld       1.00      0.79      0.89        34\n",
            "    George_W_Bush       0.84      1.00      0.91       109\n",
            "Gerhard_Schroeder       1.00      0.78      0.88        23\n",
            "      Hugo_Chavez       1.00      0.64      0.78        11\n",
            "       Tony_Blair       1.00      0.85      0.92        27\n",
            "\n",
            "         accuracy                           0.90       258\n",
            "        macro avg       0.95      0.83      0.88       258\n",
            "     weighted avg       0.92      0.90      0.90       258\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = grid.best_estimator_\n",
        "y_pred_svm = model.predict(X_test)\n",
        "# print(classification_report(y_test_encoded, y_pred_svm))\n",
        "print(\"SVM Classifier\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred_svm, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yeTVUwlQn0Kk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fab8d33-5353-4d47-d962-d35fe470ca8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Classifier\n",
            "Training Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "y_pred_svm = model.predict(X_train)\n",
        "accuracy_svm = accuracy_score(y_train_encoded, y_pred_svm)\n",
        "print(\"SVM Classifier\")\n",
        "print(\"Training Accuracy:\", accuracy_svm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oNPtFQAUn6To",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c4b7221-83dd-41ca-9140-483e842dd7ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Classifier\n",
            "Accuracy: 0.7790697674418605\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Ariel_Sharon       1.00      0.29      0.44        14\n",
            "     Colin_Powell       0.68      0.97      0.80        40\n",
            "  Donald_Rumsfeld       0.93      0.74      0.82        34\n",
            "    George_W_Bush       0.76      0.99      0.86       109\n",
            "Gerhard_Schroeder       1.00      0.17      0.30        23\n",
            "      Hugo_Chavez       0.00      0.00      0.00        11\n",
            "       Tony_Blair       0.88      0.78      0.82        27\n",
            "\n",
            "         accuracy                           0.78       258\n",
            "        macro avg       0.75      0.56      0.58       258\n",
            "     weighted avg       0.78      0.78      0.73       258\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=0.95)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "model=SVC()\n",
        "model.fit(X_train_pca, y_train_encoded)\n",
        "y_pred = model.predict(X_test_pca)\n",
        "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
        "print(\"SVM Classifier\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hTcbWrBdomCS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ecc26a1-854b-4299-de99-a84dcc851312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tuning hyperparameters via grid search\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grid search best score: 89.51%\n",
            "grid search best parameters: {'C': 0.1, 'kernel': 'linear'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = [\n",
        "        {\"kernel\":\n",
        "            [\"linear\"],\n",
        "            \"C\": [ 0.1, 1, 10, 100]},\n",
        "        {\"kernel\":\n",
        "            [\"poly\"],\n",
        "            \"degree\": [2, 3, 4],\n",
        "            \"C\": [ 0.1, 1, 10, 100]},\n",
        "        {\"kernel\":\n",
        "            [\"rbf\"],\n",
        "            \"gamma\": [\"auto\", \"scale\"],\n",
        "            \"C\": [ 0.1, 1, 10, 100]}\n",
        "]\n",
        "\n",
        "svm_clf = SVC()\n",
        "print(\"tuning hyperparameters via grid search\")\n",
        "grid = GridSearchCV(estimator=SVC(), param_grid=parameters, n_jobs=-1)\n",
        "grid.fit(X_train_pca,y_train_encoded)\n",
        "print(f\"grid search best score: {grid.best_score_ * 100:.2f}%\")\n",
        "print(f\"grid search best parameters: {grid.best_params_}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "x8QtRr0MgDSJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d98511a-8ec7-460f-bb4f-3cf8f230ceeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Classifier\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Ariel_Sharon       1.00      0.50      0.67        14\n",
            "     Colin_Powell       0.72      0.97      0.83        40\n",
            "  Donald_Rumsfeld       0.91      0.85      0.88        34\n",
            "    George_W_Bush       0.84      0.98      0.90       109\n",
            "Gerhard_Schroeder       1.00      0.52      0.69        23\n",
            "      Hugo_Chavez       1.00      0.09      0.17        11\n",
            "       Tony_Blair       0.92      0.81      0.86        27\n",
            "\n",
            "         accuracy                           0.84       258\n",
            "        macro avg       0.91      0.68      0.71       258\n",
            "     weighted avg       0.87      0.84      0.82       258\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = SVC(C= 10, gamma= 'auto', kernel= 'rbf')\n",
        "model.fit(X_train_pca,y_train_encoded)\n",
        "y_pred_svm = model.predict(X_test_pca)\n",
        "# print(classification_report(y_test_encoded, y_pred_svm))\n",
        "print(\"SVM Classifier\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred_svm, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5_sL3J87gF-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82be80ee-6860-4ab3-f22e-e53d58a6c998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Classifier\n",
            "Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "y_pred_svm = model.predict(X_train_pca)\n",
        "accuracy_svm = accuracy_score(y_train_encoded, y_pred_svm)\n",
        "print(\"SVM Classifier\")\n",
        "print(\"Accuracy:\", accuracy_svm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-gQom68SgI4t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba2e6c60-fd27-4d3a-b579-d9554291c9ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Classifier\n",
            "Accuracy: 0.8333333333333334\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Ariel_Sharon       0.91      0.71      0.80        14\n",
            "     Colin_Powell       0.95      0.88      0.91        40\n",
            "  Donald_Rumsfeld       0.96      0.76      0.85        34\n",
            "    George_W_Bush       0.75      0.98      0.85       109\n",
            "Gerhard_Schroeder       0.92      0.52      0.67        23\n",
            "      Hugo_Chavez       0.80      0.36      0.50        11\n",
            "       Tony_Blair       0.95      0.78      0.86        27\n",
            "\n",
            "         accuracy                           0.83       258\n",
            "        macro avg       0.89      0.71      0.78       258\n",
            "     weighted avg       0.86      0.83      0.83       258\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "lda = LDA(n_components=None)\n",
        "X_train_lda = lda.fit_transform(X_train, y_train_encoded)\n",
        "X_test_lda = lda.transform(X_test)\n",
        "\n",
        "model.fit(X_train_lda, y_train_encoded)\n",
        "y_pred_svm = model.predict(X_test_lda)\n",
        "accuracy_svm = accuracy_score(y_test_encoded, y_pred_svm)\n",
        "print(\"SVM Classifier\")\n",
        "print(\"Accuracy:\", accuracy_svm)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred_svm, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ooAWeF3_gKmc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27eb8923-df46-447e-e687-6a154c9328d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tuning hyperparameters via grid search\n",
            "grid search best score: 83.30%\n",
            "grid search best parameters: {'C': 0.1, 'kernel': 'linear'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = [\n",
        "        {\"kernel\":\n",
        "            [\"linear\"],\n",
        "            \"C\": [ 0.1, 1, 10, 100]},\n",
        "        {\"kernel\":\n",
        "            [\"poly\"],\n",
        "            \"degree\": [2, 3, 4],\n",
        "            \"C\": [ 0.1, 1, 10, 100]},\n",
        "        {\"kernel\":\n",
        "            [\"rbf\"],\n",
        "            \"gamma\": [\"auto\", \"scale\"],\n",
        "            \"C\": [ 0.1, 1, 10, 100]}\n",
        "]\n",
        "\n",
        "svm_clf = SVC()\n",
        "print(\"tuning hyperparameters via grid search\")\n",
        "grid = GridSearchCV(estimator=SVC(), param_grid=parameters, n_jobs=-1)\n",
        "grid.fit(X_train_lda,y_train_encoded)\n",
        "print(f\"grid search best score: {grid.best_score_ * 100:.2f}%\")\n",
        "print(f\"grid search best parameters: {grid.best_params_}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yUR4cG_QgMZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5320ab40-7581-4bac-84dd-d9a17754d840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Classifier\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Ariel_Sharon       1.00      0.50      0.67        14\n",
            "     Colin_Powell       0.95      0.90      0.92        40\n",
            "  Donald_Rumsfeld       1.00      0.65      0.79        34\n",
            "    George_W_Bush       0.69      1.00      0.81       109\n",
            "Gerhard_Schroeder       1.00      0.52      0.69        23\n",
            "      Hugo_Chavez       1.00      0.09      0.17        11\n",
            "       Tony_Blair       1.00      0.70      0.83        27\n",
            "\n",
            "         accuracy                           0.80       258\n",
            "        macro avg       0.95      0.62      0.70       258\n",
            "     weighted avg       0.86      0.80      0.78       258\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = SVC(C= 0.1, gamma= 'scale', kernel= 'rbf')\n",
        "model.fit(X_train_lda,y_train_encoded)\n",
        "y_pred_svm = model.predict(X_test_lda)\n",
        "# print(classification_report(y_test_encoded, y_pred_svm))\n",
        "print(\"SVM Classifier\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred_svm, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "sJyZ9MmEgODF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e67958e9-bacf-40c2-ef05-4ebae1eaf88d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Classifier\n",
            "Accuracy: 0.8359223300970874\n"
          ]
        }
      ],
      "source": [
        "y_pred_svm = model.predict(X_train_lda)\n",
        "accuracy_svm = accuracy_score(y_train_encoded, y_pred_svm)\n",
        "print(\"SVM Classifier\")\n",
        "print(\"Accuracy:\", accuracy_svm)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}