{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1vyoII0m7YUl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F_1HCdqdOk1s",
    "outputId": "9c3e6307-cb92-458b-e4a3-018582e75143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (1.6.12)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from kaggle) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from kaggle) (4.65.0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from kaggle) (1.26.16)\n",
      "Requirement already satisfied: bleach in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from bleach->kaggle) (23.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 23:39:33,549 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000027BECF10F90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /api/v1/datasets/metadata/jessicali9530/lfw-dataset\n",
      "2024-04-20 23:39:33,549 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000027BECF11610>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /api/v1/datasets/metadata/jessicali9530/lfw-dataset\n",
      "2024-04-20 23:39:33,549 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000027BECF11D90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /api/v1/datasets/metadata/jessicali9530/lfw-dataset\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 174, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 72, in create_connection\n",
      "    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\socket.py\", line 962, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "socket.gaierror: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 714, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 403, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1053, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 363, in connect\n",
      "    self.sock = conn = self._new_conn()\n",
      "                       ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 186, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x0000027BECF12550>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Scripts\\kaggle.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\kaggle\\cli.py\", line 54, in main\n",
      "    out = args.func(**command_args)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py\", line 1524, in dataset_download_cli\n",
      "    self.metadata_get_with_http_info(owner_slug, dataset_slug))\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\kaggle\\api\\kaggle_api.py\", line 3206, in metadata_get_with_http_info\n",
      "    return self.api_client.call_api(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\kaggle\\api_client.py\", line 313, in call_api\n",
      "    return self.__call_api(resource_path, method,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\kaggle\\api_client.py\", line 145, in __call_api\n",
      "    response_data = self.request(\n",
      "                    ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\kaggle\\api_client.py\", line 335, in request\n",
      "    return self.rest_client.GET(url,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\kaggle\\rest.py\", line 231, in GET\n",
      "    return self.request(\"GET\", url,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\kaggle\\rest.py\", line 204, in request\n",
      "    r = self.pool_manager.request(method, url,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\urllib3\\request.py\", line 74, in request\n",
      "    return self.request_encode_url(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\urllib3\\request.py\", line 96, in request_encode_url\n",
      "    return self.urlopen(method, url, **extra_kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\urllib3\\poolmanager.py\", line 376, in urlopen\n",
      "    response = conn.urlopen(method, u.request_uri, **kw)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 826, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 826, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 826, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 798, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 592, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.kaggle.com', port=443): Max retries exceeded with url: /api/v1/datasets/metadata/jessicali9530/lfw-dataset (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000027BECF12550>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'lfw-dataset.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m\n\u001b[0;32m      9\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKAGGLE_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m9464225218d56f8bfea9dd9cc437489f\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkaggle datasets download -d jessicali9530/lfw-dataset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ZipFile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlfw-dataset.zip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[0;32m     16\u001b[0m     zip_ref\u001b[38;5;241m.\u001b[39mextractall(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlfw-dataset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m os\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlfw-dataset.zip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\zipfile.py:1284\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1284\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mopen(file, filemode)\n\u001b[0;32m   1285\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lfw-dataset.zip'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "!pip install kaggle\n",
    "\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = \"majisouvik1099\"\n",
    "os.environ['KAGGLE_KEY'] = \"9464225218d56f8bfea9dd9cc437489f\"\n",
    "\n",
    "\n",
    "!kaggle datasets download -d jessicali9530/lfw-dataset\n",
    "\n",
    "\n",
    "with ZipFile('lfw-dataset.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('lfw-dataset')\n",
    "\n",
    "\n",
    "# os.remove('lfw-dataset.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0gADFqRHIgLP"
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(image_path, model):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    image = preprocess(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    features = features.squeeze(0)\n",
    "    return features\n",
    "\n",
    "\n",
    "def compute_hog(img):\n",
    "    resized_img = resize(img, (128*4, 64*4))\n",
    "    fd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8),\n",
    "                    cells_per_block=(2, 2), visualize=True, channel_axis=-1)\n",
    "    return fd\n",
    "\n",
    "\n",
    "def get_pixel(img, center, x, y):\n",
    "    new_value = 0\n",
    "    try:\n",
    "        if img[x][y] >= center:\n",
    "            new_value = 1\n",
    "    except:\n",
    "        pass\n",
    "    return new_value\n",
    "\n",
    "def lbp_calculated_pixel(img, x, y):\n",
    "    center = img[x][y]\n",
    "    val_ar = []\n",
    "    val_ar.append(get_pixel(img, center, x-1, y+1))\n",
    "    val_ar.append(get_pixel(img, center, x, y+1))\n",
    "    val_ar.append(get_pixel(img, center, x+1, y+1))\n",
    "    val_ar.append(get_pixel(img, center, x+1, y))\n",
    "    val_ar.append(get_pixel(img, center, x+1, y-1))\n",
    "    val_ar.append(get_pixel(img, center, x, y-1))\n",
    "    val_ar.append(get_pixel(img, center, x-1, y-1))\n",
    "    val_ar.append(get_pixel(img, center, x-1, y))\n",
    "\n",
    "    power_val = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "    val = 0\n",
    "    for i in range(len(val_ar)):\n",
    "        val += val_ar[i] * power_val[i]\n",
    "    return val\n",
    "\n",
    "def calcLBP(img):\n",
    "    height, width, channel = img.shape\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_lbp = np.zeros((height, width,3), np.uint8)\n",
    "    for i in range(0, height):\n",
    "        for j in range(0, width):\n",
    "             img_lbp[i, j] = lbp_calculated_pixel(img_gray, i, j)\n",
    "    hist_lbp = cv2.calcHist([img_lbp], [0], None, [256], [0, 256])\n",
    "    return hist_lbp.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JUycN27qIo3O",
    "outputId": "43a96d30-f17d-437e-a081-7fe62cab0a3d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wZjeqVQKnMcK"
   },
   "outputs": [],
   "source": [
    "lfw_folder =  r'C:\\Users\\Veeraraju_elluru\\Desktop\\Veeraraju\\IITJ\\Sophomore Year\\Sem_2\\PRML\\Project\\content\\lfw-dataset\\lfw-funneled\\lfw_funneled'\n",
    "X, y = [], []\n",
    "for folder_name in os.listdir(lfw_folder):\n",
    "    folder_path = os.path.join(lfw_folder, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        num_images = len(os.listdir(folder_path))\n",
    "        if num_images > 70:\n",
    "            for image_name in os.listdir(folder_path):\n",
    "                image_path = os.path.join(folder_path, image_name)\n",
    "                image = imread(image_path)\n",
    "                hog_feature = compute_hog(image)\n",
    "                # lbp_feature = calcLBP(image)\n",
    "                cnn_feature = extract_features(image_path, resnet).numpy()\n",
    "                hog_feature = hog_feature.reshape(-1)\n",
    "                # lbp_feature = lbp_feature.reshape(-1)\n",
    "                cnn_feature = cnn_feature.flatten()\n",
    "                combined_feature = np.concatenate((hog_feature, cnn_feature))\n",
    "\n",
    "                X.append(combined_feature)\n",
    "                y.append(folder_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MCUtZ8Feo1k3"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4lxiJIBvqJY4"
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OEwdH7OKlaxS",
    "outputId": "7ec1914a-b99a-4200-9452-fca05a9feff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning hyperparameters via grid search\n",
      "grid search best score: 89.42%\n",
      "grid search best parameters: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [\n",
    "        {\"kernel\":\n",
    "            [\"rbf\"],\n",
    "            \"gamma\": [\"auto\", \"scale\"],\n",
    "            \"C\": [0.0001, 0.001, 0.1, 1, 10, 100, 1000]}\n",
    "]\n",
    "\n",
    "svm_clf = SVC()\n",
    "print(\"tuning hyperparameters via grid search\")\n",
    "grid = GridSearchCV(estimator=SVC(), param_grid=parameters, n_jobs=-1)\n",
    "grid.fit(X_train,y_train_encoded)\n",
    "print(f\"grid search best score: {grid.best_score_ * 100:.2f}%\")\n",
    "print(f\"grid search best parameters: {grid.best_params_}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8NhrLwaazLI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SgpBOIfclc_h",
    "outputId": "0c579889-b02a-44ef-859d-0770a04d11bd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel_Sharon       1.00      0.69      0.81        16\n",
      "     Colin_Powell       0.95      0.95      0.95        41\n",
      "  Donald_Rumsfeld       0.94      0.74      0.83        23\n",
      "    George_W_Bush       0.82      1.00      0.90       112\n",
      "Gerhard_Schroeder       1.00      0.75      0.86        32\n",
      "      Hugo_Chavez       1.00      0.75      0.86        12\n",
      "       Tony_Blair       1.00      0.82      0.90        22\n",
      "\n",
      "         accuracy                           0.89       258\n",
      "        macro avg       0.96      0.81      0.87       258\n",
      "     weighted avg       0.91      0.89      0.89       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(C= 10, degree= 2, kernel= 'poly')\n",
    "model.fit(X_train,y_train_encoded)\n",
    "y_pred_svm = model.predict(X_test)\n",
    "# print(classification_report(y_test_encoded, y_pred_svm))\n",
    "print(\"SVM Classifier\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_svm, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yeTVUwlQn0Kk",
    "outputId": "6ff843ca-4dc0-48dc-cf65-536828a6a05f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "Training Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = model.predict(X_train)\n",
    "accuracy_svm = accuracy_score(y_train_encoded, y_pred_svm)\n",
    "print(\"SVM Classifier\")\n",
    "print(\"Training Accuracy:\", accuracy_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNPtFQAUn6To",
    "outputId": "7237f8c0-16e2-4bef-bbaf-d4d24879131b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "Accuracy: 0.8217054263565892\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel_Sharon       1.00      0.69      0.81        16\n",
      "     Colin_Powell       0.83      0.98      0.90        41\n",
      "  Donald_Rumsfeld       0.89      0.74      0.81        23\n",
      "    George_W_Bush       0.75      0.98      0.85       112\n",
      "Gerhard_Schroeder       1.00      0.34      0.51        32\n",
      "      Hugo_Chavez       1.00      0.42      0.59        12\n",
      "       Tony_Blair       1.00      0.82      0.90        22\n",
      "\n",
      "         accuracy                           0.82       258\n",
      "        macro avg       0.93      0.71      0.77       258\n",
      "     weighted avg       0.86      0.82      0.80       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "model=SVC()\n",
    "model.fit(X_train_pca, y_train_encoded)\n",
    "y_pred = model.predict(X_test_pca)\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(\"SVM Classifier\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KurnbFqsbX7i",
    "outputId": "c323ab61-e8ac-4678-e371-7b52acfbba4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning hyperparameters via grid search\n",
      "grid search best score: 72.14%\n",
      "grid search best parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "parameters = [\n",
    "        {\"kernel\":\n",
    "            [\"rbf\"],\n",
    "            \"gamma\": [\"auto\", \"scale\"],\n",
    "            \"C\": [0.1, 1, 10, 100,1000]}\n",
    "]\n",
    "\n",
    "svm_clf = SVC()\n",
    "print(\"tuning hyperparameters via grid search\")\n",
    "grid = GridSearchCV(estimator=SVC(), param_grid=parameters, n_jobs=-1)\n",
    "grid.fit(X_train_pca,y_train_encoded)\n",
    "print(f\"grid search best score: {grid.best_score_ * 100:.2f}%\")\n",
    "print(f\"grid search best parameters: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brlvSa1acEQe",
    "outputId": "f8e59f8d-c866-4fb8-91a4-9574f4d74886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel_Sharon       1.00      0.69      0.81        16\n",
      "     Colin_Powell       0.85      0.98      0.91        41\n",
      "  Donald_Rumsfeld       0.78      0.78      0.78        23\n",
      "    George_W_Bush       0.83      0.97      0.90       112\n",
      "Gerhard_Schroeder       0.95      0.62      0.75        32\n",
      "      Hugo_Chavez       1.00      0.58      0.74        12\n",
      "       Tony_Blair       1.00      0.82      0.90        22\n",
      "\n",
      "         accuracy                           0.86       258\n",
      "        macro avg       0.92      0.78      0.83       258\n",
      "     weighted avg       0.88      0.86      0.86       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(C= 10, gamma= 'auto', kernel= 'rbf')\n",
    "model.fit(X_train_pca,y_train_encoded)\n",
    "y_pred_svm = model.predict(X_test_pca)\n",
    "# print(classification_report(y_test_encoded, y_pred_svm))\n",
    "print(\"SVM Classifier\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_svm, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvQGQhgyc5id",
    "outputId": "ef7e2489-8874-4fb1-99dc-0e86ba678a77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = model.predict(X_train_pca)\n",
    "accuracy_svm = accuracy_score(y_train_encoded, y_pred_svm)\n",
    "print(\"SVM Classifier\")\n",
    "print(\"Accuracy:\", accuracy_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hTcbWrBdomCS",
    "outputId": "5fe0472c-e19c-484a-94e6-f37b2a6d014b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "Accuracy: 0.8449612403100775\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel_Sharon       1.00      0.75      0.86        16\n",
      "     Colin_Powell       0.88      0.93      0.90        41\n",
      "  Donald_Rumsfeld       1.00      0.70      0.82        23\n",
      "    George_W_Bush       0.79      0.97      0.87       112\n",
      "Gerhard_Schroeder       0.95      0.56      0.71        32\n",
      "      Hugo_Chavez       0.62      0.67      0.64        12\n",
      "       Tony_Blair       1.00      0.77      0.87        22\n",
      "\n",
      "         accuracy                           0.84       258\n",
      "        macro avg       0.89      0.76      0.81       258\n",
      "     weighted avg       0.87      0.84      0.84       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA(n_components=None)\n",
    "X_train_lda = lda.fit_transform(X_train, y_train_encoded)\n",
    "X_test_lda = lda.transform(X_test)\n",
    "\n",
    "model.fit(X_train_lda, y_train_encoded)\n",
    "y_pred_svm = model.predict(X_test_lda)\n",
    "accuracy_svm = accuracy_score(y_test_encoded, y_pred_svm)\n",
    "print(\"SVM Classifier\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_svm, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfzwFPI5dAcV",
    "outputId": "d6f12fa9-8d16-40a9-c7a8-c1599fdd6b0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning hyperparameters via grid search\n",
      "grid search best score: 82.62%\n",
      "grid search best parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [\n",
    "        {\"kernel\":\n",
    "            [\"rbf\"],\n",
    "            \"gamma\": [\"auto\", \"scale\"],\n",
    "            \"C\": [0.1, 1, 10, 100,1000]}\n",
    "]\n",
    "\n",
    "svm_clf = SVC()\n",
    "print(\"tuning hyperparameters via grid search\")\n",
    "grid = GridSearchCV(estimator=SVC(), param_grid=parameters, n_jobs=-1)\n",
    "grid.fit(X_train_lda,y_train_encoded)\n",
    "print(f\"grid search best score: {grid.best_score_ * 100:.2f}%\")\n",
    "print(f\"grid search best parameters: {grid.best_params_}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3XP3IsXddSpK",
    "outputId": "51389ebc-1b95-47c5-92cd-41b1c5c38295"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel_Sharon       1.00      0.69      0.81        16\n",
      "     Colin_Powell       0.95      0.93      0.94        41\n",
      "  Donald_Rumsfeld       0.93      0.61      0.74        23\n",
      "    George_W_Bush       0.68      1.00      0.81       112\n",
      "Gerhard_Schroeder       1.00      0.25      0.40        32\n",
      "      Hugo_Chavez       1.00      0.42      0.59        12\n",
      "       Tony_Blair       1.00      0.64      0.78        22\n",
      "\n",
      "         accuracy                           0.78       258\n",
      "        macro avg       0.94      0.65      0.72       258\n",
      "     weighted avg       0.85      0.78      0.76       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(C= 0.1, gamma= 'scale', kernel= 'rbf')\n",
    "model.fit(X_train_lda,y_train_encoded)\n",
    "y_pred_svm = model.predict(X_test_lda)\n",
    "# print(classification_report(y_test_encoded, y_pred_svm))\n",
    "print(\"SVM Classifier\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_svm, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wfQHL2UFdmZ7",
    "outputId": "de5f8028-7082-4e45-f93a-8597bb11d437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "Accuracy: 0.8126213592233009\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = model.predict(X_train_lda)\n",
    "accuracy_svm = accuracy_score(y_train_encoded, y_pred_svm)\n",
    "print(\"SVM Classifier\")\n",
    "print(\"Accuracy:\", accuracy_svm)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
