{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1vyoII0m7YUl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F_1HCdqdOk1s",
    "outputId": "9c3e6307-cb92-458b-e4a3-018582e75143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (1.6.12)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from kaggle) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from kaggle) (4.65.0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from kaggle) (1.26.16)\n",
      "Requirement already satisfied: bleach in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from bleach->kaggle) (23.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\veeraraju_elluru\\anaconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/112M [00:00<?, ?B/s]\n",
      "  1%|          | 1.00M/112M [00:01<02:48, 693kB/s]\n",
      "  2%|1         | 2.00M/112M [00:01<01:23, 1.39MB/s]\n",
      "  3%|2         | 3.00M/112M [00:01<00:51, 2.23MB/s]\n",
      "  4%|3         | 4.00M/112M [00:01<00:36, 3.15MB/s]\n",
      "  4%|4         | 5.00M/112M [00:02<00:27, 4.02MB/s]\n",
      "  5%|5         | 6.00M/112M [00:02<00:23, 4.84MB/s]\n",
      "  6%|6         | 7.00M/112M [00:02<00:19, 5.63MB/s]\n",
      "  7%|7         | 8.00M/112M [00:02<00:17, 6.32MB/s]\n",
      "  8%|8         | 9.00M/112M [00:02<00:15, 6.89MB/s]\n",
      "  9%|8         | 10.0M/112M [00:02<00:14, 7.35MB/s]\n",
      " 10%|9         | 11.0M/112M [00:02<00:13, 7.65MB/s]\n",
      " 11%|#         | 12.0M/112M [00:02<00:13, 7.80MB/s]\n",
      " 12%|#1        | 13.0M/112M [00:03<00:13, 7.74MB/s]\n",
      " 12%|#2        | 14.0M/112M [00:03<00:12, 8.01MB/s]\n",
      " 13%|#3        | 15.0M/112M [00:03<00:12, 8.03MB/s]\n",
      " 14%|#4        | 16.0M/112M [00:03<00:12, 8.12MB/s]\n",
      " 15%|#5        | 17.0M/112M [00:03<00:12, 8.26MB/s]\n",
      " 16%|#6        | 18.0M/112M [00:03<00:12, 8.24MB/s]\n",
      " 17%|#6        | 19.0M/112M [00:03<00:11, 8.79MB/s]\n",
      " 19%|#8        | 21.0M/112M [00:04<00:08, 10.7MB/s]\n",
      " 20%|##        | 23.0M/112M [00:04<00:08, 11.3MB/s]\n",
      " 22%|##2       | 25.0M/112M [00:04<00:08, 11.2MB/s]\n",
      " 24%|##4       | 27.0M/112M [00:04<00:07, 11.4MB/s]\n",
      " 26%|##5       | 29.0M/112M [00:04<00:07, 11.9MB/s]\n",
      " 28%|##7       | 31.0M/112M [00:04<00:07, 12.1MB/s]\n",
      " 29%|##9       | 33.0M/112M [00:05<00:06, 12.2MB/s]\n",
      " 31%|###1      | 35.0M/112M [00:05<00:06, 13.4MB/s]\n",
      " 33%|###2      | 37.0M/112M [00:05<00:05, 14.2MB/s]\n",
      " 35%|###4      | 39.0M/112M [00:05<00:05, 15.4MB/s]\n",
      " 36%|###6      | 41.0M/112M [00:05<00:04, 15.8MB/s]\n",
      " 38%|###8      | 43.0M/112M [00:05<00:04, 15.9MB/s]\n",
      " 40%|####      | 45.0M/112M [00:05<00:04, 15.6MB/s]\n",
      " 42%|####1     | 47.0M/112M [00:05<00:04, 16.3MB/s]\n",
      " 44%|####3     | 49.0M/112M [00:06<00:04, 16.0MB/s]\n",
      " 45%|####5     | 51.0M/112M [00:06<00:03, 16.4MB/s]\n",
      " 47%|####7     | 53.0M/112M [00:06<00:03, 16.3MB/s]\n",
      " 49%|####8     | 55.0M/112M [00:06<00:05, 12.0MB/s]\n",
      " 51%|#####     | 57.0M/112M [00:06<00:04, 13.4MB/s]\n",
      " 52%|#####2    | 59.0M/112M [00:06<00:03, 15.0MB/s]\n",
      " 54%|#####4    | 61.0M/112M [00:06<00:03, 15.4MB/s]\n",
      " 56%|#####6    | 63.0M/112M [00:07<00:03, 16.2MB/s]\n",
      " 58%|#####7    | 65.0M/112M [00:07<00:02, 16.7MB/s]\n",
      " 60%|#####9    | 67.0M/112M [00:07<00:02, 17.1MB/s]\n",
      " 61%|######1   | 69.0M/112M [00:07<00:02, 17.4MB/s]\n",
      " 63%|######3   | 71.0M/112M [00:07<00:02, 16.8MB/s]\n",
      " 65%|######4   | 73.0M/112M [00:07<00:02, 17.2MB/s]\n",
      " 67%|######6   | 75.0M/112M [00:07<00:02, 17.6MB/s]\n",
      " 68%|######8   | 77.0M/112M [00:07<00:02, 17.7MB/s]\n",
      " 70%|#######   | 79.0M/112M [00:07<00:01, 17.6MB/s]\n",
      " 72%|#######2  | 81.0M/112M [00:08<00:01, 17.8MB/s]\n",
      " 74%|#######3  | 83.0M/112M [00:08<00:01, 18.3MB/s]\n",
      " 76%|#######5  | 85.0M/112M [00:08<00:01, 18.4MB/s]\n",
      " 77%|#######7  | 87.0M/112M [00:08<00:01, 17.7MB/s]\n",
      " 79%|#######9  | 89.0M/112M [00:08<00:01, 18.2MB/s]\n",
      " 81%|########  | 91.0M/112M [00:08<00:01, 17.4MB/s]\n",
      " 83%|########2 | 93.0M/112M [00:08<00:01, 17.7MB/s]\n",
      " 84%|########4 | 95.0M/112M [00:08<00:01, 17.2MB/s]\n",
      " 86%|########6 | 97.0M/112M [00:09<00:00, 17.3MB/s]\n",
      " 88%|########8 | 99.0M/112M [00:09<00:00, 17.0MB/s]\n",
      " 90%|########9 | 101M/112M [00:09<00:00, 17.4MB/s] \n",
      " 92%|#########1| 103M/112M [00:09<00:00, 17.6MB/s]\n",
      " 93%|#########3| 105M/112M [00:09<00:00, 17.7MB/s]\n",
      " 95%|#########5| 107M/112M [00:09<00:00, 14.4MB/s]\n",
      " 97%|#########6| 109M/112M [00:09<00:00, 15.6MB/s]\n",
      " 99%|#########8| 111M/112M [00:09<00:00, 16.8MB/s]\n",
      "100%|##########| 112M/112M [00:10<00:00, 11.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/jessicali9530/lfw-dataset\n",
      "License(s): other\n",
      "Downloading lfw-dataset.zip to C:\\Users\\Veeraraju_elluru\\Desktop\\Veeraraju\\IITJ\\Sophomore Year\\Sem_2\\PRML\\Project\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "!pip install kaggle\n",
    "\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = \"majisouvik1099\"\n",
    "os.environ['KAGGLE_KEY'] = \"9464225218d56f8bfea9dd9cc437489f\"\n",
    "\n",
    "\n",
    "!kaggle datasets download -d jessicali9530/lfw-dataset\n",
    "\n",
    "\n",
    "with ZipFile('lfw-dataset.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('lfw-dataset')\n",
    "\n",
    "\n",
    "os.remove('lfw-dataset.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0gADFqRHIgLP"
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(image_path, model):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    image = preprocess(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    features = features.squeeze(0)\n",
    "    return features\n",
    "\n",
    "\n",
    "def compute_hog(img):\n",
    "    resized_img = resize(img, (128*4, 64*4))\n",
    "    fd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8),\n",
    "                    cells_per_block=(2, 2), visualize=True, channel_axis=-1)\n",
    "    return fd\n",
    "\n",
    "\n",
    "def get_pixel(img, center, x, y):\n",
    "    new_value = 0\n",
    "    try:\n",
    "        if img[x][y] >= center:\n",
    "            new_value = 1\n",
    "    except:\n",
    "        pass\n",
    "    return new_value\n",
    "\n",
    "def lbp_calculated_pixel(img, x, y):\n",
    "    center = img[x][y]\n",
    "    val_ar = []\n",
    "    val_ar.append(get_pixel(img, center, x-1, y+1))\n",
    "    val_ar.append(get_pixel(img, center, x, y+1))\n",
    "    val_ar.append(get_pixel(img, center, x+1, y+1))\n",
    "    val_ar.append(get_pixel(img, center, x+1, y))\n",
    "    val_ar.append(get_pixel(img, center, x+1, y-1))\n",
    "    val_ar.append(get_pixel(img, center, x, y-1))\n",
    "    val_ar.append(get_pixel(img, center, x-1, y-1))\n",
    "    val_ar.append(get_pixel(img, center, x-1, y))\n",
    "\n",
    "    power_val = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "    val = 0\n",
    "    for i in range(len(val_ar)):\n",
    "        val += val_ar[i] * power_val[i]\n",
    "    return val\n",
    "\n",
    "def calcLBP(img):\n",
    "    height, width, channel = img.shape\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_lbp = np.zeros((height, width,3), np.uint8)\n",
    "    for i in range(0, height):\n",
    "        for j in range(0, width):\n",
    "             img_lbp[i, j] = lbp_calculated_pixel(img_gray, i, j)\n",
    "    hist_lbp = cv2.calcHist([img_lbp], [0], None, [256], [0, 256])\n",
    "    return hist_lbp.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JUycN27qIo3O",
    "outputId": "43a96d30-f17d-437e-a081-7fe62cab0a3d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wZjeqVQKnMcK"
   },
   "outputs": [],
   "source": [
    "lfw_folder =  r'C:\\Users\\Veeraraju_elluru\\Desktop\\Veeraraju\\IITJ\\Sophomore Year\\Sem_2\\PRML\\Project\\content\\lfw-dataset\\lfw-funneled\\lfw_funneled'\n",
    "X, y = [], []\n",
    "for folder_name in os.listdir(lfw_folder):\n",
    "    folder_path = os.path.join(lfw_folder, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        num_images = len(os.listdir(folder_path))\n",
    "        if num_images > 70:\n",
    "            for image_name in os.listdir(folder_path):\n",
    "                image_path = os.path.join(folder_path, image_name)\n",
    "                image = imread(image_path)\n",
    "                hog_feature = compute_hog(image)\n",
    "                lbp_feature = calcLBP(image)\n",
    "                cnn_feature = extract_features(image_path, resnet).numpy()\n",
    "                hog_feature = hog_feature.reshape(-1)\n",
    "                lbp_feature = lbp_feature.reshape(-1)\n",
    "                cnn_feature = cnn_feature.flatten()\n",
    "                combined_feature = np.concatenate((hog_feature, cnn_feature, lbp_feature))\n",
    "\n",
    "                X.append(combined_feature)\n",
    "                y.append(folder_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MCUtZ8Feo1k3"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4lxiJIBvqJY4"
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OEwdH7OKlaxS",
    "outputId": "7ec1914a-b99a-4200-9452-fca05a9feff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning hyperparameters via grid search\n",
      "grid search best score: 43.20%\n",
      "grid search best parameters: {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [\n",
    "        {\"kernel\":\n",
    "            [\"rbf\"],\n",
    "            \"gamma\": [\"auto\", \"scale\"],\n",
    "            \"C\": [0.0001, 0.001, 0.1, 1, 10, 100, 1000]}\n",
    "]\n",
    "\n",
    "svm_clf = SVC()\n",
    "print(\"tuning hyperparameters via grid search\")\n",
    "grid = GridSearchCV(estimator=SVC(), param_grid=parameters, n_jobs=-1)\n",
    "grid.fit(X_train,y_train_encoded)\n",
    "print(f\"grid search best score: {grid.best_score_ * 100:.2f}%\")\n",
    "print(f\"grid search best parameters: {grid.best_params_}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8NhrLwaazLI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SgpBOIfclc_h",
    "outputId": "0c579889-b02a-44ef-859d-0770a04d11bd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel_Sharon       0.00      0.00      0.00        16\n",
      "     Colin_Powell       0.00      0.00      0.00        41\n",
      "  Donald_Rumsfeld       0.00      0.00      0.00        23\n",
      "    George_W_Bush       0.43      1.00      0.61       112\n",
      "Gerhard_Schroeder       0.00      0.00      0.00        32\n",
      "      Hugo_Chavez       0.00      0.00      0.00        12\n",
      "       Tony_Blair       0.00      0.00      0.00        22\n",
      "\n",
      "         accuracy                           0.43       258\n",
      "        macro avg       0.06      0.14      0.09       258\n",
      "     weighted avg       0.19      0.43      0.26       258\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = SVC(C= 10, degree= 2, kernel= 'poly')\n",
    "model.fit(X_train,y_train_encoded)\n",
    "y_pred_svm = model.predict(X_test)\n",
    "# print(classification_report(y_test_encoded, y_pred_svm))\n",
    "print(\"SVM Classifier\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_svm, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yeTVUwlQn0Kk",
    "outputId": "6ff843ca-4dc0-48dc-cf65-536828a6a05f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "Training Accuracy: 0.40679611650485437\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = model.predict(X_train)\n",
    "accuracy_svm = accuracy_score(y_train_encoded, y_pred_svm)\n",
    "print(\"SVM Classifier\")\n",
    "print(\"Training Accuracy:\", accuracy_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNPtFQAUn6To",
    "outputId": "7237f8c0-16e2-4bef-bbaf-d4d24879131b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "Accuracy: 0.43410852713178294\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel_Sharon       0.00      0.00      0.00        16\n",
      "     Colin_Powell       0.00      0.00      0.00        41\n",
      "  Donald_Rumsfeld       0.00      0.00      0.00        23\n",
      "    George_W_Bush       0.43      1.00      0.61       112\n",
      "Gerhard_Schroeder       0.00      0.00      0.00        32\n",
      "      Hugo_Chavez       0.00      0.00      0.00        12\n",
      "       Tony_Blair       0.00      0.00      0.00        22\n",
      "\n",
      "         accuracy                           0.43       258\n",
      "        macro avg       0.06      0.14      0.09       258\n",
      "     weighted avg       0.19      0.43      0.26       258\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "model=SVC()\n",
    "model.fit(X_train_pca, y_train_encoded)\n",
    "y_pred = model.predict(X_test_pca)\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(\"SVM Classifier\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KurnbFqsbX7i",
    "outputId": "c323ab61-e8ac-4678-e371-7b52acfbba4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning hyperparameters via grid search\n",
      "grid search best score: 40.58%\n",
      "grid search best parameters: {'C': 0.1, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "parameters = [\n",
    "        {\"kernel\":\n",
    "            [\"rbf\"],\n",
    "            \"gamma\": [\"auto\", \"scale\"],\n",
    "            \"C\": [0.1, 1, 10, 100,1000]}\n",
    "]\n",
    "\n",
    "svm_clf = SVC()\n",
    "print(\"tuning hyperparameters via grid search\")\n",
    "grid = GridSearchCV(estimator=SVC(), param_grid=parameters, n_jobs=-1)\n",
    "grid.fit(X_train_pca,y_train_encoded)\n",
    "print(f\"grid search best score: {grid.best_score_ * 100:.2f}%\")\n",
    "print(f\"grid search best parameters: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brlvSa1acEQe",
    "outputId": "f8e59f8d-c866-4fb8-91a4-9574f4d74886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel_Sharon       0.00      0.00      0.00        16\n",
      "     Colin_Powell       0.00      0.00      0.00        41\n",
      "  Donald_Rumsfeld       0.00      0.00      0.00        23\n",
      "    George_W_Bush       0.43      1.00      0.61       112\n",
      "Gerhard_Schroeder       0.00      0.00      0.00        32\n",
      "      Hugo_Chavez       0.00      0.00      0.00        12\n",
      "       Tony_Blair       0.00      0.00      0.00        22\n",
      "\n",
      "         accuracy                           0.43       258\n",
      "        macro avg       0.06      0.14      0.09       258\n",
      "     weighted avg       0.19      0.43      0.26       258\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Veeraraju_elluru\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = SVC(C= 10, gamma= 'auto', kernel= 'rbf')\n",
    "model.fit(X_train_pca,y_train_encoded)\n",
    "y_pred_svm = model.predict(X_test_pca)\n",
    "# print(classification_report(y_test_encoded, y_pred_svm))\n",
    "print(\"SVM Classifier\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_svm, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvQGQhgyc5id",
    "outputId": "ef7e2489-8874-4fb1-99dc-0e86ba678a77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = model.predict(X_train_pca)\n",
    "accuracy_svm = accuracy_score(y_train_encoded, y_pred_svm)\n",
    "print(\"SVM Classifier\")\n",
    "print(\"Accuracy:\", accuracy_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hTcbWrBdomCS",
    "outputId": "5fe0472c-e19c-484a-94e6-f37b2a6d014b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "Accuracy: 0.8527131782945736\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel_Sharon       1.00      0.75      0.86        16\n",
      "     Colin_Powell       0.89      0.95      0.92        41\n",
      "  Donald_Rumsfeld       1.00      0.70      0.82        23\n",
      "    George_W_Bush       0.80      0.97      0.88       112\n",
      "Gerhard_Schroeder       1.00      0.59      0.75        32\n",
      "      Hugo_Chavez       0.62      0.67      0.64        12\n",
      "       Tony_Blair       1.00      0.77      0.87        22\n",
      "\n",
      "         accuracy                           0.85       258\n",
      "        macro avg       0.90      0.77      0.82       258\n",
      "     weighted avg       0.88      0.85      0.85       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA(n_components=None)\n",
    "X_train_lda = lda.fit_transform(X_train, y_train_encoded)\n",
    "X_test_lda = lda.transform(X_test)\n",
    "\n",
    "model.fit(X_train_lda, y_train_encoded)\n",
    "y_pred_svm = model.predict(X_test_lda)\n",
    "accuracy_svm = accuracy_score(y_test_encoded, y_pred_svm)\n",
    "print(\"SVM Classifier\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_svm, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfzwFPI5dAcV",
    "outputId": "d6f12fa9-8d16-40a9-c7a8-c1599fdd6b0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning hyperparameters via grid search\n",
      "grid search best score: 82.62%\n",
      "grid search best parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [\n",
    "        {\"kernel\":\n",
    "            [\"rbf\"],\n",
    "            \"gamma\": [\"auto\", \"scale\"],\n",
    "            \"C\": [0.1, 1, 10, 100,1000]}\n",
    "]\n",
    "\n",
    "svm_clf = SVC()\n",
    "print(\"tuning hyperparameters via grid search\")\n",
    "grid = GridSearchCV(estimator=SVC(), param_grid=parameters, n_jobs=-1)\n",
    "grid.fit(X_train_lda,y_train_encoded)\n",
    "print(f\"grid search best score: {grid.best_score_ * 100:.2f}%\")\n",
    "print(f\"grid search best parameters: {grid.best_params_}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3XP3IsXddSpK",
    "outputId": "51389ebc-1b95-47c5-92cd-41b1c5c38295"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel_Sharon       1.00      0.69      0.81        16\n",
      "     Colin_Powell       0.95      0.93      0.94        41\n",
      "  Donald_Rumsfeld       0.93      0.61      0.74        23\n",
      "    George_W_Bush       0.68      1.00      0.81       112\n",
      "Gerhard_Schroeder       1.00      0.28      0.44        32\n",
      "      Hugo_Chavez       1.00      0.42      0.59        12\n",
      "       Tony_Blair       1.00      0.64      0.78        22\n",
      "\n",
      "         accuracy                           0.79       258\n",
      "        macro avg       0.94      0.65      0.73       258\n",
      "     weighted avg       0.85      0.79      0.77       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(C= 0.1, gamma= 'scale', kernel= 'rbf')\n",
    "model.fit(X_train_lda,y_train_encoded)\n",
    "y_pred_svm = model.predict(X_test_lda)\n",
    "# print(classification_report(y_test_encoded, y_pred_svm))\n",
    "print(\"SVM Classifier\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_svm, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wfQHL2UFdmZ7",
    "outputId": "de5f8028-7082-4e45-f93a-8597bb11d437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "Accuracy: 0.8097087378640777\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = model.predict(X_train_lda)\n",
    "accuracy_svm = accuracy_score(y_train_encoded, y_pred_svm)\n",
    "print(\"SVM Classifier\")\n",
    "print(\"Accuracy:\", accuracy_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
