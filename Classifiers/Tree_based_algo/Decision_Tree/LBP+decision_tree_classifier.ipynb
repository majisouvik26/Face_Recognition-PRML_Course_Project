{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vyoII0m7YUl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from skimage.feature import hog\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_1HCdqdOk1s",
        "outputId": "6ec3deb1-a167-43d7-88e5-8757deb789d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n",
            "Downloading lfw-dataset.zip to /content\n",
            " 86% 97.0M/112M [00:01<00:00, 97.3MB/s]\n",
            "100% 112M/112M [00:01<00:00, 98.9MB/s] \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "\n",
        "!pip install kaggle\n",
        "\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = \"majisouvik1099\"\n",
        "os.environ['KAGGLE_KEY'] = \"9464225218d56f8bfea9dd9cc437489f\"\n",
        "\n",
        "\n",
        "!kaggle datasets download -d jessicali9530/lfw-dataset\n",
        "\n",
        "\n",
        "with ZipFile('lfw-dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('lfw-dataset')\n",
        "\n",
        "\n",
        "os.remove('lfw-dataset.zip')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gADFqRHIgLP"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_features(image_path, model):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    image = preprocess(image)\n",
        "    image = image.unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        features = model(image)\n",
        "    features = features.squeeze(0)\n",
        "    return features\n",
        "\n",
        "\n",
        "def compute_hog(img):\n",
        "    resized_img = resize(img, (128*4, 64*4))\n",
        "    fd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8),\n",
        "                    cells_per_block=(2, 2), visualize=True, multichannel=True)\n",
        "    return fd\n",
        "\n",
        "\n",
        "def get_pixel(img, center, x, y):\n",
        "    new_value = 0\n",
        "    try:\n",
        "        if img[x][y] >= center:\n",
        "            new_value = 1\n",
        "    except:\n",
        "        pass\n",
        "    return new_value\n",
        "\n",
        "def lbp_calculated_pixel(img, x, y):\n",
        "    center = img[x][y]\n",
        "    val_ar = []\n",
        "    val_ar.append(get_pixel(img, center, x-1, y+1))\n",
        "    val_ar.append(get_pixel(img, center, x, y+1))\n",
        "    val_ar.append(get_pixel(img, center, x+1, y+1))\n",
        "    val_ar.append(get_pixel(img, center, x+1, y))\n",
        "    val_ar.append(get_pixel(img, center, x+1, y-1))\n",
        "    val_ar.append(get_pixel(img, center, x, y-1))\n",
        "    val_ar.append(get_pixel(img, center, x-1, y-1))\n",
        "    val_ar.append(get_pixel(img, center, x-1, y))\n",
        "\n",
        "    power_val = [1, 2, 4, 8, 16, 32, 64, 128]\n",
        "    val = 0\n",
        "    for i in range(len(val_ar)):\n",
        "        val += val_ar[i] * power_val[i]\n",
        "    return val\n",
        "\n",
        "def calcLBP(img):\n",
        "    height, width, channel = img.shape\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img_lbp = np.zeros((height, width,3), np.uint8)\n",
        "    for i in range(0, height):\n",
        "        for j in range(0, width):\n",
        "             img_lbp[i, j] = lbp_calculated_pixel(img_gray, i, j)\n",
        "    hist_lbp = cv2.calcHist([img_lbp], [0], None, [256], [0, 256])\n",
        "    return hist_lbp.flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUycN27qIo3O",
        "outputId": "0dc6fb58-7e4d-4be6-9f6b-888b361697a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 83.5MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): ReLU(inplace=True)\n",
              "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (6): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (7): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "resnet = models.resnet50(pretrained=True)\n",
        "resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
        "resnet.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lfw_folder = '/content/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled'\n",
        "X, y = [], []\n",
        "for folder_name in os.listdir(lfw_folder):\n",
        "    folder_path = os.path.join(lfw_folder, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "        num_images = len(os.listdir(folder_path))\n",
        "        if num_images > 70:\n",
        "            for image_name in os.listdir(folder_path):\n",
        "                image_path = os.path.join(folder_path, image_name)\n",
        "                image = imread(image_path)\n",
        "                hog_feature = compute_hog(image)\n",
        "                lbp_feature = calcLBP(image)\n",
        "                # cnn_feature = extract_features(image_path, resnet).numpy()\n",
        "                # hog_feature = hog_feature.reshape(-1)\n",
        "                lbp_feature = lbp_feature.reshape(-1)\n",
        "                # cnn_feature = cnn_feature.flatten()\n",
        "                # combined_feature = np.concatenate((hog_feature, lbp_feature, cnn_feature))\n",
        "\n",
        "                X.append(lbp_feature)\n",
        "                y.append(folder_name)\n"
      ],
      "metadata": {
        "id": "wZjeqVQKnMcK",
        "outputId": "dc54011f-d6ab-4ed5-d731-34c2793e1399",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-8d0f7df1f55f>:19: FutureWarning: `multichannel` is a deprecated argument name for `hog`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  fd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lbp_feature"
      ],
      "metadata": {
        "id": "mUofteubfY_C",
        "outputId": "30ec0e95-97f3-4e0e-c17c-76c595d6d553",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.7200e+02, 3.7000e+01, 3.0300e+02, 1.5100e+02, 2.2000e+01,\n",
              "       6.0000e+00, 1.3100e+02, 2.8700e+02, 3.2800e+02, 1.3000e+01,\n",
              "       2.8000e+01, 2.4000e+01, 1.6900e+02, 6.0000e+00, 8.0300e+02,\n",
              "       1.5170e+03, 5.9000e+01, 6.0000e+00, 1.8000e+01, 1.8000e+01,\n",
              "       9.0000e+00, 0.0000e+00, 4.0000e+00, 1.4000e+01, 1.5200e+02,\n",
              "       8.0000e+00, 3.2000e+01, 2.7000e+01, 3.7700e+02, 1.0000e+01,\n",
              "       1.8210e+03, 1.0240e+03, 3.4200e+02, 2.5000e+01, 4.9500e+02,\n",
              "       4.9000e+01, 2.4000e+01, 4.0000e+00, 3.1000e+01, 1.5000e+01,\n",
              "       1.2000e+01, 1.0000e+00, 7.0000e+00, 3.0000e+00, 1.8000e+01,\n",
              "       0.0000e+00, 3.4000e+01, 1.8000e+01, 1.8100e+02, 1.6000e+01,\n",
              "       4.3000e+01, 1.2000e+01, 4.0000e+00, 0.0000e+00, 1.5000e+01,\n",
              "       1.0000e+01, 6.9200e+02, 2.9000e+01, 4.8000e+01, 2.9000e+01,\n",
              "       1.5530e+03, 1.9000e+01, 2.4800e+03, 4.3900e+02, 4.3000e+01,\n",
              "       5.0000e+00, 2.0000e+01, 5.0000e+00, 4.0000e+00, 0.0000e+00,\n",
              "       1.6000e+01, 1.1000e+01, 2.4000e+01, 2.0000e+00, 1.0000e+00,\n",
              "       1.0000e+00, 1.5000e+01, 0.0000e+00, 3.1000e+01, 3.2000e+01,\n",
              "       5.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
              "       0.0000e+00, 2.0000e+00, 1.0000e+00, 9.0000e+00, 0.0000e+00,\n",
              "       2.0000e+00, 1.0000e+00, 8.0000e+00, 1.0000e+00, 3.6000e+01,\n",
              "       2.7000e+01, 1.4900e+02, 1.0000e+01, 4.8000e+01, 1.8000e+01,\n",
              "       8.0000e+00, 1.0000e+00, 1.1000e+01, 1.8000e+01, 2.2000e+01,\n",
              "       0.0000e+00, 1.0000e+00, 1.0000e+00, 2.1000e+01, 1.0000e+00,\n",
              "       1.4000e+01, 1.6000e+01, 3.5700e+02, 1.1000e+01, 2.4000e+01,\n",
              "       1.3000e+01, 1.4000e+01, 1.0000e+00, 8.0000e+00, 4.1000e+01,\n",
              "       1.8350e+03, 3.0000e+01, 2.6000e+01, 2.3000e+01, 8.0200e+02,\n",
              "       1.7000e+01, 4.8300e+02, 4.5400e+02, 3.8800e+02, 1.6700e+02,\n",
              "       1.8000e+01, 5.7500e+02, 2.0000e+01, 7.0000e+00, 1.3000e+01,\n",
              "       1.3370e+03, 6.2600e+02, 4.5000e+01, 4.0000e+00, 3.5000e+01,\n",
              "       3.9000e+01, 1.6000e+01, 4.7000e+01, 2.1280e+03, 1.8000e+01,\n",
              "       1.5000e+01, 0.0000e+00, 3.2000e+01, 5.0000e+00, 0.0000e+00,\n",
              "       0.0000e+00, 2.4000e+01, 2.5000e+01, 1.6000e+01, 0.0000e+00,\n",
              "       3.2000e+01, 1.9000e+01, 1.0000e+01, 2.4000e+01, 4.6700e+02,\n",
              "       2.7000e+01, 4.2000e+01, 1.0000e+01, 5.1000e+01, 0.0000e+00,\n",
              "       3.0000e+00, 1.0000e+00, 1.5000e+01, 0.0000e+00, 2.0000e+00,\n",
              "       1.0000e+00, 1.0000e+00, 2.0000e+00, 2.0000e+00, 2.0000e+00,\n",
              "       2.7000e+01, 4.4000e+01, 2.6000e+01, 1.0000e+00, 1.9000e+01,\n",
              "       1.0000e+00, 0.0000e+00, 2.0000e+00, 2.4000e+01, 2.5000e+01,\n",
              "       3.2000e+01, 2.0000e+00, 1.8000e+01, 1.7000e+01, 2.0000e+01,\n",
              "       2.7000e+01, 3.0600e+02, 1.4100e+02, 3.6400e+02, 2.4000e+01,\n",
              "       1.2670e+03, 1.2000e+01, 1.0000e+01, 1.2000e+01, 7.5700e+02,\n",
              "       4.9000e+01, 1.8000e+01, 0.0000e+00, 1.7000e+01, 1.6000e+01,\n",
              "       2.0000e+01, 3.2000e+01, 4.3900e+02, 6.0000e+00, 8.0000e+00,\n",
              "       2.0000e+00, 2.5000e+01, 3.0000e+00, 0.0000e+00, 1.0000e+00,\n",
              "       2.0000e+01, 1.1000e+01, 8.0000e+00, 0.0000e+00, 1.9000e+01,\n",
              "       1.3000e+01, 6.5000e+01, 1.9000e+01, 3.6800e+02, 7.8700e+02,\n",
              "       1.4970e+03, 5.0000e+01, 2.8690e+03, 4.5000e+01, 3.1000e+01,\n",
              "       3.3000e+01, 5.3900e+02, 6.5000e+01, 2.9000e+01, 0.0000e+00,\n",
              "       4.8000e+01, 2.5000e+01, 1.4000e+01, 2.4000e+01, 4.4300e+02,\n",
              "       2.0860e+03, 1.0170e+03, 2.2000e+01, 5.7500e+02, 4.1000e+01,\n",
              "       2.3000e+01, 1.8000e+01, 5.2500e+02, 3.1220e+03, 5.9400e+02,\n",
              "       1.7000e+01, 4.0800e+02, 5.1300e+02, 4.4500e+02, 3.4200e+02,\n",
              "       1.6298e+04], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)"
      ],
      "metadata": {
        "id": "MCUtZ8Feo1k3"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "4lxiJIBvqJY4"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree without PCA or LDA"
      ],
      "metadata": {
        "id": "O_adzYReqU78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf = DecisionTreeClassifier()\n",
        "dt_clf.fit(X_train, y_train_encoded)\n",
        "y_pred_dt = dt_clf.predict(X_test)\n",
        "accuracy_dt = accuracy_score(y_test_encoded, y_pred_dt)\n",
        "print(\"Decision Tree Classifier\")\n",
        "print(\"Accuracy:\", accuracy_dt)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred_dt, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFOQz50kqRDj",
        "outputId": "f09867bd-5ff4-44a7-b315-96b5a0bd02cb"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier\n",
            "Accuracy: 0.34108527131782945\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Ariel_Sharon       0.12      0.07      0.09        14\n",
            "     Colin_Powell       0.25      0.33      0.29        40\n",
            "  Donald_Rumsfeld       0.27      0.18      0.21        34\n",
            "    George_W_Bush       0.51      0.54      0.53       109\n",
            "Gerhard_Schroeder       0.10      0.09      0.09        23\n",
            "      Hugo_Chavez       0.12      0.18      0.15        11\n",
            "       Tony_Blair       0.20      0.19      0.19        27\n",
            "\n",
            "         accuracy                           0.34       258\n",
            "        macro avg       0.23      0.22      0.22       258\n",
            "     weighted avg       0.33      0.34      0.33       258\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using some hyperparameters"
      ],
      "metadata": {
        "id": "jMO3zE0ntJyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf = DecisionTreeClassifier(ccp_alpha=0.01, class_weight=None, criterion='entropy',\n",
        "                       max_depth=5, max_features='sqrt', max_leaf_nodes=None,\n",
        "                       min_impurity_decrease=0.0,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0,\n",
        "                       random_state=1024, splitter='best')\n",
        "dt_clf.fit(X_train, y_train_encoded)\n",
        "y_pred_dt = dt_clf.predict(X_test)\n",
        "accuracy_dt = accuracy_score(y_test_encoded, y_pred_dt)\n",
        "\n",
        "print(\"Decision Tree Classifier\")\n",
        "print(\"Accuracy:\", accuracy_dt)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred_dt, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpE3iZb_ttPL",
        "outputId": "05380fb0-368e-4c13-b3d0-0d8b92ee431d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier\n",
            "Accuracy: 0.3875968992248062\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Ariel_Sharon       0.08      0.07      0.08        14\n",
            "     Colin_Powell       0.29      0.25      0.27        40\n",
            "  Donald_Rumsfeld       0.25      0.15      0.19        34\n",
            "    George_W_Bush       0.44      0.77      0.56       109\n",
            "Gerhard_Schroeder       0.00      0.00      0.00        23\n",
            "      Hugo_Chavez       0.00      0.00      0.00        11\n",
            "       Tony_Blair       0.00      0.00      0.00        27\n",
            "\n",
            "         accuracy                           0.39       258\n",
            "        macro avg       0.15      0.18      0.16       258\n",
            "     weighted avg       0.27      0.39      0.31       258\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree with PCA"
      ],
      "metadata": {
        "id": "uQIMdC_Oqcq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=0.95)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "dt_clf.fit(X_train_pca, y_train_encoded)\n",
        "y_pred_dt = dt_clf.predict(X_test_pca)\n",
        "accuracy_dt = accuracy_score(y_test_encoded, y_pred_dt)\n",
        "\n",
        "print(\"Decision Tree Classifier\")\n",
        "print(\"Accuracy:\", accuracy_dt)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred_dt, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "192bHd9aqa0X",
        "outputId": "2d5743f9-546b-455f-cbc6-cacaaa2f6cc3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier\n",
            "Accuracy: 0.29069767441860467\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Ariel_Sharon       0.00      0.00      0.00        14\n",
            "     Colin_Powell       0.26      0.35      0.30        40\n",
            "  Donald_Rumsfeld       0.32      0.26      0.29        34\n",
            "    George_W_Bush       0.43      0.42      0.43       109\n",
            "Gerhard_Schroeder       0.08      0.09      0.08        23\n",
            "      Hugo_Chavez       0.09      0.09      0.09        11\n",
            "       Tony_Blair       0.13      0.11      0.12        27\n",
            "\n",
            "         accuracy                           0.29       258\n",
            "        macro avg       0.19      0.19      0.19       258\n",
            "     weighted avg       0.29      0.29      0.29       258\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf = DecisionTreeClassifier(ccp_alpha=0.01, class_weight=None, criterion='entropy',\n",
        "                       max_depth=5, max_features='sqrt', max_leaf_nodes=None,\n",
        "                       min_impurity_decrease=0.0,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0,\n",
        "                       random_state=1024, splitter='best')\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "dt_clf.fit(X_train_pca, y_train_encoded)\n",
        "y_pred_dt = dt_clf.predict(X_test_pca)\n",
        "accuracy_dt = accuracy_score(y_test_encoded, y_pred_dt)\n",
        "\n",
        "print(\"Decision Tree Classifier\")\n",
        "print(\"Accuracy:\", accuracy_dt)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred_dt, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJ7t3AHwugqh",
        "outputId": "6b725e29-eb85-4318-8609-e5e2fd9ca8f3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier\n",
            "Accuracy: 0.41472868217054265\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Ariel_Sharon       0.00      0.00      0.00        14\n",
            "     Colin_Powell       0.30      0.23      0.26        40\n",
            "  Donald_Rumsfeld       0.33      0.06      0.10        34\n",
            "    George_W_Bush       0.44      0.88      0.59       109\n",
            "Gerhard_Schroeder       0.00      0.00      0.00        23\n",
            "      Hugo_Chavez       0.00      0.00      0.00        11\n",
            "       Tony_Blair       0.00      0.00      0.00        27\n",
            "\n",
            "         accuracy                           0.41       258\n",
            "        macro avg       0.15      0.17      0.14       258\n",
            "     weighted avg       0.28      0.41      0.30       258\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree with LDA"
      ],
      "metadata": {
        "id": "OKnaza1LrDw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "lda = LDA(n_components=None)\n",
        "X_train_lda = lda.fit_transform(X_train, y_train_encoded)\n",
        "X_test_lda = lda.transform(X_test)\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "dt_clf.fit(X_train_lda, y_train_encoded)\n",
        "y_pred_dt = dt_clf.predict(X_test_lda)\n",
        "accuracy_dt = accuracy_score(y_test_encoded, y_pred_dt)\n",
        "print(\"Decision Tree Classifier\")\n",
        "print(\"Accuracy:\", accuracy_dt)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred_dt, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_lW-a22rGcL",
        "outputId": "704c14b7-6659-4d3d-e66f-47a9474eff05"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier\n",
            "Accuracy: 0.32170542635658916\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Ariel_Sharon       0.12      0.07      0.09        14\n",
            "     Colin_Powell       0.29      0.38      0.33        40\n",
            "  Donald_Rumsfeld       0.13      0.09      0.11        34\n",
            "    George_W_Bush       0.56      0.46      0.51       109\n",
            "Gerhard_Schroeder       0.20      0.26      0.23        23\n",
            "      Hugo_Chavez       0.08      0.09      0.09        11\n",
            "       Tony_Blair       0.16      0.26      0.19        27\n",
            "\n",
            "         accuracy                           0.32       258\n",
            "        macro avg       0.22      0.23      0.22       258\n",
            "     weighted avg       0.34      0.32      0.33       258\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf = DecisionTreeClassifier(ccp_alpha=0.01, class_weight=None, criterion='entropy',\n",
        "                       max_depth=5, max_features='sqrt', max_leaf_nodes=None,\n",
        "                       min_impurity_decrease=0.0,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0,\n",
        "                       random_state=1024, splitter='best')\n",
        "\n",
        "dt_clf.fit(X_train_lda, y_train_encoded)\n",
        "y_pred_dt = dt_clf.predict(X_test_lda)\n",
        "accuracy_dt = accuracy_score(y_test_encoded, y_pred_dt)\n",
        "\n",
        "print(\"Decision Tree Classifier\")\n",
        "print(\"Accuracy:\", accuracy_dt)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred_dt, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDsHgjZEuy05",
        "outputId": "0cca8b09-54ad-4ff5-df53-bfe5018ce6bf"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier\n",
            "Accuracy: 0.37209302325581395\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Ariel_Sharon       0.43      0.21      0.29        14\n",
            "     Colin_Powell       0.27      0.42      0.33        40\n",
            "  Donald_Rumsfeld       0.27      0.18      0.21        34\n",
            "    George_W_Bush       0.51      0.59      0.55       109\n",
            "Gerhard_Schroeder       0.00      0.00      0.00        23\n",
            "      Hugo_Chavez       0.00      0.00      0.00        11\n",
            "       Tony_Blair       0.18      0.22      0.20        27\n",
            "\n",
            "         accuracy                           0.37       258\n",
            "        macro avg       0.24      0.23      0.22       258\n",
            "     weighted avg       0.34      0.37      0.35       258\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}