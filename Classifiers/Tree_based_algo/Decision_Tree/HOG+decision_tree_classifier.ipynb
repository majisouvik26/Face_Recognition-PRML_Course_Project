{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1vyoII0m7YUl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from skimage.feature import hog\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_1HCdqdOk1s",
        "outputId": "e6936713-fea6-4a63-bdc2-1228a38d6fee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n",
            "Downloading lfw-dataset.zip to /content\n",
            "100% 112M/112M [00:01<00:00, 133MB/s]  \n",
            "100% 112M/112M [00:01<00:00, 116MB/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "\n",
        "!pip install kaggle\n",
        "\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = \"majisouvik1099\"\n",
        "os.environ['KAGGLE_KEY'] = \"9464225218d56f8bfea9dd9cc437489f\"\n",
        "\n",
        "\n",
        "!kaggle datasets download -d jessicali9530/lfw-dataset\n",
        "\n",
        "\n",
        "with ZipFile('lfw-dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('lfw-dataset')\n",
        "\n",
        "\n",
        "os.remove('lfw-dataset.zip')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0gADFqRHIgLP"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_features(image_path, model):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    image = preprocess(image)\n",
        "    image = image.unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        features = model(image)\n",
        "    features = features.squeeze(0)\n",
        "    return features\n",
        "\n",
        "\n",
        "def compute_hog(img):\n",
        "    resized_img = resize(img, (128*4, 64*4))\n",
        "    fd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8),\n",
        "                    cells_per_block=(2, 2), visualize=True, multichannel=True)\n",
        "    return fd\n",
        "\n",
        "\n",
        "def get_pixel(img, center, x, y):\n",
        "    new_value = 0\n",
        "    try:\n",
        "        if img[x][y] >= center:\n",
        "            new_value = 1\n",
        "    except:\n",
        "        pass\n",
        "    return new_value\n",
        "\n",
        "def lbp_calculated_pixel(img, x, y):\n",
        "    center = img[x][y]\n",
        "    val_ar = []\n",
        "    val_ar.append(get_pixel(img, center, x-1, y+1))\n",
        "    val_ar.append(get_pixel(img, center, x, y+1))\n",
        "    val_ar.append(get_pixel(img, center, x+1, y+1))\n",
        "    val_ar.append(get_pixel(img, center, x+1, y))\n",
        "    val_ar.append(get_pixel(img, center, x+1, y-1))\n",
        "    val_ar.append(get_pixel(img, center, x, y-1))\n",
        "    val_ar.append(get_pixel(img, center, x-1, y-1))\n",
        "    val_ar.append(get_pixel(img, center, x-1, y))\n",
        "\n",
        "    power_val = [1, 2, 4, 8, 16, 32, 64, 128]\n",
        "    val = 0\n",
        "    for i in range(len(val_ar)):\n",
        "        val += val_ar[i] * power_val[i]\n",
        "    return val\n",
        "\n",
        "def calcLBP(img):\n",
        "    height, width, channel = img.shape\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img_lbp = np.zeros((height, width,3), np.uint8)\n",
        "    for i in range(0, height):\n",
        "        for j in range(0, width):\n",
        "             img_lbp[i, j] = lbp_calculated_pixel(img_gray, i, j)\n",
        "    hist_lbp = cv2.calcHist([img_lbp], [0], None, [256], [0, 256])\n",
        "    return hist_lbp.flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUycN27qIo3O",
        "outputId": "7ff422d0-01a0-410c-f3d0-e2f7945bbd50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): ReLU(inplace=True)\n",
              "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (6): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (7): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "resnet = models.resnet50(pretrained=True)\n",
        "resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
        "resnet.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lfw_folder = '/content/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled'\n",
        "X, y = [], []\n",
        "for folder_name in os.listdir(lfw_folder):\n",
        "    folder_path = os.path.join(lfw_folder, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "        num_images = len(os.listdir(folder_path))\n",
        "        if num_images > 70:\n",
        "            for image_name in os.listdir(folder_path):\n",
        "                image_path = os.path.join(folder_path, image_name)\n",
        "                image = imread(image_path)\n",
        "                hog_feature = compute_hog(image)\n",
        "                # lbp_feature = calcLBP(image)\n",
        "                # cnn_feature = extract_features(image_path, resnet).numpy()\n",
        "                hog_feature = hog_feature.reshape(-1)\n",
        "                # lbp_feature = lbp_feature.reshape(-1)\n",
        "                # cnn_feature = cnn_feature.flatten()\n",
        "                # combined_feature = np.concatenate((hog_feature, lbp_feature, cnn_feature))\n",
        "\n",
        "                X.append(hog_feature)\n",
        "                y.append(folder_name)\n"
      ],
      "metadata": {
        "id": "wZjeqVQKnMcK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c8219ec-e285-498e-c842-52764c316609"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-8d0f7df1f55f>:19: FutureWarning: `multichannel` is a deprecated argument name for `hog`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  fd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)"
      ],
      "metadata": {
        "id": "MCUtZ8Feo1k3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "4lxiJIBvqJY4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree without PCA or LDA"
      ],
      "metadata": {
        "id": "O_adzYReqU78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf = DecisionTreeClassifier()\n",
        "dt_clf.fit(X_train, y_train_encoded)\n",
        "y_pred_dt = dt_clf.predict(X_test)\n",
        "accuracy_dt = accuracy_score(y_test_encoded, y_pred_dt)\n",
        "print(\"Decision Tree Classifier\")\n",
        "print(\"Accuracy:\", accuracy_dt)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred_dt, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFOQz50kqRDj",
        "outputId": "5911a522-0003-4d2a-bbf1-5367ce6b85b6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier\n",
            "Accuracy: 0.6085271317829457\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Ariel_Sharon       0.28      0.36      0.31        14\n",
            "     Colin_Powell       0.55      0.57      0.56        40\n",
            "  Donald_Rumsfeld       0.50      0.38      0.43        34\n",
            "    George_W_Bush       0.76      0.83      0.80       109\n",
            "Gerhard_Schroeder       0.53      0.35      0.42        23\n",
            "      Hugo_Chavez       0.29      0.18      0.22        11\n",
            "       Tony_Blair       0.48      0.56      0.52        27\n",
            "\n",
            "         accuracy                           0.61       258\n",
            "        macro avg       0.48      0.46      0.47       258\n",
            "     weighted avg       0.60      0.61      0.60       258\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using some hyperparameters"
      ],
      "metadata": {
        "id": "jMO3zE0ntJyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf = DecisionTreeClassifier(ccp_alpha=0.01, class_weight=None, criterion='entropy',\n",
        "                       max_depth=5, max_features='sqrt', max_leaf_nodes=None,\n",
        "                       min_impurity_decrease=0.0,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0,\n",
        "                       random_state=1024, splitter='best')\n",
        "dt_clf.fit(X_train, y_train_encoded)\n",
        "y_pred_dt = dt_clf.predict(X_test)\n",
        "accuracy_dt = accuracy_score(y_test_encoded, y_pred_dt)\n",
        "\n",
        "print(\"Decision Tree Classifier\")\n",
        "print(\"Accuracy:\", accuracy_dt)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred_dt, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpE3iZb_ttPL",
        "outputId": "274ff84b-ccb3-4c7d-c7f7-95d3c5211f74"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier\n",
            "Accuracy: 0.5116279069767442\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Ariel_Sharon       0.45      0.36      0.40        14\n",
            "     Colin_Powell       0.53      0.53      0.53        40\n",
            "  Donald_Rumsfeld       0.36      0.29      0.32        34\n",
            "    George_W_Bush       0.55      0.83      0.66       109\n",
            "Gerhard_Schroeder       0.75      0.13      0.22        23\n",
            "      Hugo_Chavez       0.00      0.00      0.00        11\n",
            "       Tony_Blair       0.40      0.07      0.12        27\n",
            "\n",
            "         accuracy                           0.51       258\n",
            "        macro avg       0.43      0.32      0.32       258\n",
            "     weighted avg       0.49      0.51      0.46       258\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree with PCA"
      ],
      "metadata": {
        "id": "uQIMdC_Oqcq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=0.95)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "dt_clf.fit(X_train_pca, y_train_encoded)\n",
        "y_pred_dt = dt_clf.predict(X_test_pca)\n",
        "accuracy_dt = accuracy_score(y_test_encoded, y_pred_dt)\n",
        "\n",
        "print(\"Decision Tree Classifier\")\n",
        "print(\"Accuracy:\", accuracy_dt)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred_dt, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "192bHd9aqa0X",
        "outputId": "3a9426f2-eab8-4e3b-ffbf-5f16925f8af5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier\n",
            "Accuracy: 0.47674418604651164\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Ariel_Sharon       0.27      0.29      0.28        14\n",
            "     Colin_Powell       0.40      0.68      0.50        40\n",
            "  Donald_Rumsfeld       0.70      0.21      0.32        34\n",
            "    George_W_Bush       0.66      0.65      0.66       109\n",
            "Gerhard_Schroeder       0.11      0.09      0.10        23\n",
            "      Hugo_Chavez       0.12      0.09      0.11        11\n",
            "       Tony_Blair       0.34      0.41      0.37        27\n",
            "\n",
            "         accuracy                           0.48       258\n",
            "        macro avg       0.37      0.34      0.33       258\n",
            "     weighted avg       0.50      0.48      0.46       258\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf = DecisionTreeClassifier(ccp_alpha=0.01, class_weight=None, criterion='entropy',\n",
        "                       max_depth=5, max_features='sqrt', max_leaf_nodes=None,\n",
        "                       min_impurity_decrease=0.0,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0,\n",
        "                       random_state=1024, splitter='best')\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "dt_clf.fit(X_train_pca, y_train_encoded)\n",
        "y_pred_dt = dt_clf.predict(X_test_pca)\n",
        "accuracy_dt = accuracy_score(y_test_encoded, y_pred_dt)\n",
        "\n",
        "print(\"Decision Tree Classifier\")\n",
        "print(\"Accuracy:\", accuracy_dt)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred_dt, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJ7t3AHwugqh",
        "outputId": "a56d1ca6-53ad-465d-9769-667d149545c8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier\n",
            "Accuracy: 0.437984496124031\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Ariel_Sharon       0.17      0.07      0.10        14\n",
            "     Colin_Powell       0.50      0.10      0.17        40\n",
            "  Donald_Rumsfeld       0.50      0.09      0.15        34\n",
            "    George_W_Bush       0.44      0.91      0.59       109\n",
            "Gerhard_Schroeder       0.00      0.00      0.00        23\n",
            "      Hugo_Chavez       0.00      0.00      0.00        11\n",
            "       Tony_Blair       0.50      0.22      0.31        27\n",
            "\n",
            "         accuracy                           0.44       258\n",
            "        macro avg       0.30      0.20      0.19       258\n",
            "     weighted avg       0.39      0.44      0.33       258\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree with LDA"
      ],
      "metadata": {
        "id": "OKnaza1LrDw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "lda = LDA(n_components=None)\n",
        "X_train_lda = lda.fit_transform(X_train, y_train_encoded)\n",
        "X_test_lda = lda.transform(X_test)\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "dt_clf.fit(X_train_lda, y_train_encoded)\n",
        "y_pred_dt = dt_clf.predict(X_test_lda)\n",
        "accuracy_dt = accuracy_score(y_test_encoded, y_pred_dt)\n",
        "print(\"Decision Tree Classifier\")\n",
        "print(\"Accuracy:\", accuracy_dt)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred_dt, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_lW-a22rGcL",
        "outputId": "277c091c-c546-48d1-fc96-2ff9230654f4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier\n",
            "Accuracy: 0.7790697674418605\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Ariel_Sharon       0.67      0.57      0.62        14\n",
            "     Colin_Powell       0.81      0.85      0.83        40\n",
            "  Donald_Rumsfeld       0.92      0.65      0.76        34\n",
            "    George_W_Bush       0.79      0.95      0.87       109\n",
            "Gerhard_Schroeder       0.76      0.57      0.65        23\n",
            "      Hugo_Chavez       0.43      0.27      0.33        11\n",
            "       Tony_Blair       0.68      0.63      0.65        27\n",
            "\n",
            "         accuracy                           0.78       258\n",
            "        macro avg       0.72      0.64      0.67       258\n",
            "     weighted avg       0.78      0.78      0.77       258\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf = DecisionTreeClassifier(ccp_alpha=0.01, class_weight=None, criterion='entropy',\n",
        "                       max_depth=5, max_features='sqrt', max_leaf_nodes=None,\n",
        "                       min_impurity_decrease=0.0,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0,\n",
        "                       random_state=1024, splitter='best')\n",
        "\n",
        "dt_clf.fit(X_train_lda, y_train_encoded)\n",
        "y_pred_dt = dt_clf.predict(X_test_lda)\n",
        "accuracy_dt = accuracy_score(y_test_encoded, y_pred_dt)\n",
        "\n",
        "print(\"Decision Tree Classifier\")\n",
        "print(\"Accuracy:\", accuracy_dt)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred_dt, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDsHgjZEuy05",
        "outputId": "500c633c-84e0-4bc9-bc06-db921243da4b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier\n",
            "Accuracy: 0.7054263565891473\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Ariel_Sharon       1.00      0.36      0.53        14\n",
            "     Colin_Powell       0.77      0.82      0.80        40\n",
            "  Donald_Rumsfeld       0.75      0.09      0.16        34\n",
            "    George_W_Bush       0.66      0.98      0.79       109\n",
            "Gerhard_Schroeder       0.59      0.70      0.64        23\n",
            "      Hugo_Chavez       0.00      0.00      0.00        11\n",
            "       Tony_Blair       1.00      0.67      0.80        27\n",
            "\n",
            "         accuracy                           0.71       258\n",
            "        macro avg       0.68      0.52      0.53       258\n",
            "     weighted avg       0.71      0.71      0.65       258\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}