{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":34595,"sourceType":"datasetVersion","datasetId":26922}],"dockerImageVersionId":30702,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# importing important libraries and its functionalities\nimport os\nimport cv2\nimport numpy as np\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom skimage.feature import hog\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier","metadata":{"id":"1vyoII0m7YUl","execution":{"iopub.status.busy":"2024-04-21T01:16:45.840849Z","iopub.status.idle":"2024-04-21T01:16:45.841452Z","shell.execute_reply.started":"2024-04-21T01:16:45.841171Z","shell.execute_reply":"2024-04-21T01:16:45.841197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom zipfile import ZipFile\n\n\n!pip install kaggle\n\n\nos.environ['KAGGLE_USERNAME'] = \"majisouvik1099\"\nos.environ['KAGGLE_KEY'] = \"9464225218d56f8bfea9dd9cc437489f\"\n\n# download the datset needed\n!kaggle datasets download -d jessicali9530/lfw-dataset\n\n# extract the files by unzipping\nwith ZipFile('lfw-dataset.zip', 'r') as zip_ref:\n    zip_ref.extractall('lfw-dataset')\n\n\nos.remove('lfw-dataset.zip')\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F_1HCdqdOk1s","outputId":"62ae2229-8cc1-4ccd-acef-04407371f563","execution":{"iopub.status.busy":"2024-04-21T01:16:45.843240Z","iopub.status.idle":"2024-04-21T01:16:45.843791Z","shell.execute_reply.started":"2024-04-21T01:16:45.843523Z","shell.execute_reply":"2024-04-21T01:16:45.843546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# defining some of the important functions that are needed \n\n# defining feature extraction for resnet-50\ndef extract_features(image_path, model):\n    image = Image.open(image_path).convert('RGB')\n    preprocess = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n    image = preprocess(image)\n    image = image.unsqueeze(0)\n    with torch.no_grad():\n        features = model(image)\n    features = features.squeeze(0)\n    return features\n\n# hog calculation\ndef compute_hog(img):\n    resized_img = resize(img, (128*4, 64*4))\n    fd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8),\n                    cells_per_block=(2, 2), visualize=True,channel_axis=-1)\n    return fd\n\n\ndef get_pixel(img, center, x, y):\n    new_value = 0\n    try:\n        if img[x][y] >= center:\n            new_value = 1\n    except:\n        pass\n    return new_value\n\n# calculate lbp\n\ndef lbp_calculated_pixel(img, x, y):\n    center = img[x][y]\n    val_ar = []\n    val_ar.append(get_pixel(img, center, x-1, y+1))\n    val_ar.append(get_pixel(img, center, x, y+1))\n    val_ar.append(get_pixel(img, center, x+1, y+1))\n    val_ar.append(get_pixel(img, center, x+1, y))\n    val_ar.append(get_pixel(img, center, x+1, y-1))\n    val_ar.append(get_pixel(img, center, x, y-1))\n    val_ar.append(get_pixel(img, center, x-1, y-1))\n    val_ar.append(get_pixel(img, center, x-1, y))\n\n    power_val = [1, 2, 4, 8, 16, 32, 64, 128]\n    val = 0\n    for i in range(len(val_ar)):\n        val += val_ar[i] * power_val[i]\n    return val\n\ndef calcLBP(img):\n    height, width, channel = img.shape\n    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img_lbp = np.zeros((height, width,3), np.uint8)\n    for i in range(0, height):\n        for j in range(0, width):\n             img_lbp[i, j] = lbp_calculated_pixel(img_gray, i, j)\n    hist_lbp = cv2.calcHist([img_lbp], [0], None, [256], [0, 256])\n    return hist_lbp.flatten()\n","metadata":{"id":"0gADFqRHIgLP","execution":{"iopub.status.busy":"2024-04-21T01:30:33.551587Z","iopub.execute_input":"2024-04-21T01:30:33.552098Z","iopub.status.idle":"2024-04-21T01:30:33.571707Z","shell.execute_reply.started":"2024-04-21T01:30:33.552062Z","shell.execute_reply":"2024-04-21T01:30:33.570159Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# pretrained resnet-50 model\nresnet = models.resnet50(pretrained=True)\nresnet = nn.Sequential(*list(resnet.children())[:-1])\nresnet.eval()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JUycN27qIo3O","outputId":"b08ac631-81af-4e5b-8bc5-a61eb1dba2d6","execution":{"iopub.status.busy":"2024-04-21T01:22:19.712520Z","iopub.execute_input":"2024-04-21T01:22:19.712915Z","iopub.status.idle":"2024-04-21T01:22:20.433157Z","shell.execute_reply.started":"2024-04-21T01:22:19.712881Z","shell.execute_reply":"2024-04-21T01:22:20.431920Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Sequential(\n  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU(inplace=True)\n  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (5): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (6): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (7): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n)"},"metadata":{}}]},{"cell_type":"code","source":"# extracting the features from the folder\nlfw_folder = '/kaggle/input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled'\nX, y = [], []\nfor folder_name in os.listdir(lfw_folder):\n    folder_path = os.path.join(lfw_folder, folder_name)\n    if os.path.isdir(folder_path):\n        num_images = len(os.listdir(folder_path))\n        if num_images > 70: # taking those persons who have atleast 70 images \n            for image_name in os.listdir(folder_path):\n                image_path = os.path.join(folder_path, image_name)\n                image = imread(image_path)\n                hog_feature = compute_hog(image) # hog features\n                lbp_feature = calcLBP(image)     # lbp features\n                cnn_feature = extract_features(image_path, resnet).numpy() #cnn features\n                hog_feature = hog_feature.reshape(-1) \n                lbp_feature = lbp_feature.reshape(-1)\n                cnn_feature = cnn_feature.flatten()\n                combined_feature = np.concatenate((hog_feature, lbp_feature, cnn_feature)) # combining features as needed\n\n                X.append(combined_feature)\n                y.append(folder_name)\n","metadata":{"id":"wZjeqVQKnMcK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6facf535-cdb4-47f6-932e-6725d7448b40","execution":{"iopub.status.busy":"2024-04-21T03:41:19.253823Z","iopub.execute_input":"2024-04-21T03:41:19.254292Z","iopub.status.idle":"2024-04-21T04:08:23.581456Z","shell.execute_reply.started":"2024-04-21T03:41:19.254261Z","shell.execute_reply":"2024-04-21T04:08:23.580093Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# hog features extracted\nhog_feature","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mUofteubfY_C","outputId":"3619593a-ad6c-4b04-b9f1-4e05892e656a","execution":{"iopub.status.busy":"2024-04-21T04:08:23.584033Z","iopub.execute_input":"2024-04-21T04:08:23.584481Z","iopub.status.idle":"2024-04-21T04:08:23.594602Z","shell.execute_reply.started":"2024-04-21T04:08:23.584448Z","shell.execute_reply":"2024-04-21T04:08:23.593291Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"array([0., 0., 0., ..., 0., 0., 0.])"},"metadata":{}}]},{"cell_type":"code","source":"# printing the shape\nnp.array(X).shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jwXoqblCx22_","outputId":"cc4088cf-2ed8-4e71-e5b3-c3889abcb9a0","execution":{"iopub.status.busy":"2024-04-21T04:08:23.596230Z","iopub.execute_input":"2024-04-21T04:08:23.597097Z","iopub.status.idle":"2024-04-21T04:08:24.464663Z","shell.execute_reply.started":"2024-04-21T04:08:23.597051Z","shell.execute_reply":"2024-04-21T04:08:24.463491Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"(1288, 72612)"},"metadata":{}}]},{"cell_type":"code","source":"# train-test split \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)","metadata":{"id":"MCUtZ8Feo1k3","execution":{"iopub.status.busy":"2024-04-21T04:08:24.467546Z","iopub.execute_input":"2024-04-21T04:08:24.468058Z","iopub.status.idle":"2024-04-21T04:08:24.476385Z","shell.execute_reply.started":"2024-04-21T04:08:24.468014Z","shell.execute_reply":"2024-04-21T04:08:24.474991Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nimport numpy as np\n\n# Grid\nparam_grid = {'C': np.logspace(-3, 3, 7)}\n\n# L1 regularization\nlasso_logreg = LogisticRegression(penalty='l1', solver='liblinear', max_iter=10000)\n\n# find the best hyperparameters\ngrid_search = GridSearchCV(lasso_logreg, param_grid, cv=5)\n\ngrid_search.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T04:08:24.477972Z","iopub.execute_input":"2024-04-21T04:08:24.478437Z","iopub.status.idle":"2024-04-21T05:52:57.986074Z","shell.execute_reply.started":"2024-04-21T04:08:24.478393Z","shell.execute_reply":"2024-04-21T05:52:57.983985Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=5,\n             estimator=LogisticRegression(max_iter=10000, penalty='l1',\n                                          solver='liblinear'),\n             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])})","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n             estimator=LogisticRegression(max_iter=10000, penalty=&#x27;l1&#x27;,\n                                          solver=&#x27;liblinear&#x27;),\n             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n             estimator=LogisticRegression(max_iter=10000, penalty=&#x27;l1&#x27;,\n                                          solver=&#x27;liblinear&#x27;),\n             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"# best model\nbest_lasso_logreg = grid_search.best_estimator_\n\n# Fit the model\nbest_lasso_logreg.fit(X_train, y_train)\n\n# prediction\ny_pred = best_lasso_logreg.predict(X_test)\n\n# Evaluation\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n# classification report\nreport = classification_report(y_test, y_pred)\n\nprint(\"Classification Report:\\n\", report)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T05:52:57.989193Z","iopub.execute_input":"2024-04-21T05:52:57.990108Z","iopub.status.idle":"2024-04-21T05:54:21.679361Z","shell.execute_reply.started":"2024-04-21T05:52:57.990058Z","shell.execute_reply":"2024-04-21T05:54:21.675508Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Accuracy: 0.9573643410852714\nClassification Report:\n                    precision    recall  f1-score   support\n\n     Ariel_Sharon       1.00      0.86      0.92        14\n     Colin_Powell       0.93      0.93      0.93        43\n  Donald_Rumsfeld       1.00      1.00      1.00        24\n    George_W_Bush       0.97      0.98      0.98       124\nGerhard_Schroeder       0.94      0.94      0.94        18\n      Hugo_Chavez       0.92      0.92      0.92        13\n       Tony_Blair       0.91      0.91      0.91        22\n\n         accuracy                           0.96       258\n        macro avg       0.95      0.94      0.94       258\n     weighted avg       0.96      0.96      0.96       258\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# prediction\ny_pred = best_lasso_logreg.predict(X_train)\n\n# Evaluation\naccuracy = accuracy_score(y_train, y_pred)\nprint(\"Accuracy:\", accuracy)\n# classification report\nreport = classification_report(y_train, y_pred)\n\nprint(\"Classification Report:\\n\", report)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T05:54:21.681255Z","iopub.execute_input":"2024-04-21T05:54:21.682026Z","iopub.status.idle":"2024-04-21T05:54:22.128785Z","shell.execute_reply.started":"2024-04-21T05:54:21.681984Z","shell.execute_reply":"2024-04-21T05:54:22.125518Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Accuracy: 1.0\nClassification Report:\n                    precision    recall  f1-score   support\n\n     Ariel_Sharon       1.00      1.00      1.00        63\n     Colin_Powell       1.00      1.00      1.00       193\n  Donald_Rumsfeld       1.00      1.00      1.00        97\n    George_W_Bush       1.00      1.00      1.00       406\nGerhard_Schroeder       1.00      1.00      1.00        91\n      Hugo_Chavez       1.00      1.00      1.00        58\n       Tony_Blair       1.00      1.00      1.00       122\n\n         accuracy                           1.00      1030\n        macro avg       1.00      1.00      1.00      1030\n     weighted avg       1.00      1.00      1.00      1030\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=0.95)\nX_train_pca = pca.fit_transform(X_train)\nX_test_pca = pca.transform(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T05:54:22.134771Z","iopub.execute_input":"2024-04-21T05:54:22.138002Z","iopub.status.idle":"2024-04-21T05:54:56.744897Z","shell.execute_reply.started":"2024-04-21T05:54:22.137925Z","shell.execute_reply":"2024-04-21T05:54:56.743639Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nlda = LDA(n_components=None)\nX_train_lda = lda.fit_transform(X_train, y_train_encoded)\nX_test_lda = lda.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T05:54:56.747246Z","iopub.execute_input":"2024-04-21T05:54:56.748374Z","iopub.status.idle":"2024-04-21T05:55:38.509250Z","shell.execute_reply.started":"2024-04-21T05:54:56.748325Z","shell.execute_reply":"2024-04-21T05:55:38.507884Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# best model\nbest_lasso_logreg = grid_search.best_estimator_\n\n# Fit the model\nbest_lasso_logreg.fit(X_train_pca, y_train)\n\n# Mprediction\ny_pred = best_lasso_logreg.predict(X_test_pca)\n\n# Evaluation\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n# classification report\nreport = classification_report(y_test, y_pred)\n\nprint(\"Classification Report:\\n\", report)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T05:55:38.513772Z","iopub.execute_input":"2024-04-21T05:55:38.514428Z","iopub.status.idle":"2024-04-21T05:55:38.557628Z","shell.execute_reply.started":"2024-04-21T05:55:38.514381Z","shell.execute_reply":"2024-04-21T05:55:38.553954Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Accuracy: 0.49224806201550386\nClassification Report:\n                    precision    recall  f1-score   support\n\n     Ariel_Sharon       0.00      0.00      0.00        14\n     Colin_Powell       0.40      0.40      0.40        43\n  Donald_Rumsfeld       0.40      0.08      0.14        24\n    George_W_Bush       0.51      0.87      0.64       124\nGerhard_Schroeder       0.00      0.00      0.00        18\n      Hugo_Chavez       0.00      0.00      0.00        13\n       Tony_Blair       0.00      0.00      0.00        22\n\n         accuracy                           0.49       258\n        macro avg       0.19      0.19      0.17       258\n     weighted avg       0.35      0.49      0.39       258\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"# best model\nbest_lasso_logreg = grid_search.best_estimator_\n\n# Fit the model\nbest_lasso_logreg.fit(X_train_lda, y_train)\n\n# Mprediction\ny_pred = best_lasso_logreg.predict(X_test_lda)\n\n# Evaluation\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n# classification report\nreport = classification_report(y_test, y_pred)\n\nprint(\"Classification Report:\\n\", report)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T05:55:38.559448Z","iopub.execute_input":"2024-04-21T05:55:38.559884Z","iopub.status.idle":"2024-04-21T05:55:38.607531Z","shell.execute_reply.started":"2024-04-21T05:55:38.559842Z","shell.execute_reply":"2024-04-21T05:55:38.606242Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Accuracy: 0.8875968992248062\nClassification Report:\n                    precision    recall  f1-score   support\n\n     Ariel_Sharon       1.00      0.64      0.78        14\n     Colin_Powell       0.89      0.93      0.91        43\n  Donald_Rumsfeld       0.95      0.83      0.89        24\n    George_W_Bush       0.86      0.99      0.92       124\nGerhard_Schroeder       0.93      0.72      0.81        18\n      Hugo_Chavez       1.00      0.38      0.56        13\n       Tony_Blair       0.90      0.86      0.88        22\n\n         accuracy                           0.89       258\n        macro avg       0.93      0.77      0.82       258\n     weighted avg       0.90      0.89      0.88       258\n\n","output_type":"stream"}]}]}